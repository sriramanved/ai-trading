{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMjwq6pS-kFz"
      },
      "source": [
        "# Stock NeurIPS2018 Part 2. Train\n",
        "This series is a reproduction of *the process in the paper Practical Deep Reinforcement Learning Approach for Stock Trading*. \n",
        "\n",
        "This is the second part of the NeurIPS2018 series, introducing how to use FinRL to make data into the gym form environment, and train DRL agents on it.\n",
        "\n",
        "Other demos can be found at the repo of [FinRL-Tutorials](https://github.com/AI4Finance-Foundation/FinRL-Tutorials)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT-zXutMgqOS"
      },
      "source": [
        "# Part 1. Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xt1317y2ixSS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "# from customenv import StockTradingEnv\n",
        "# from finrl.env.env_stocktrading import StockTradingEnv\n",
        "from custommodels import DRLAgent\n",
        "from stable_baselines3.common.logger import configure\n",
        "from finrl import config_tickers\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
        "\n",
        "check_and_make_directories([TRAINED_MODEL_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWrSrQv3i0Ng"
      },
      "source": [
        "# Part 2. Build A Market Environment in OpenAI Gym-style"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiHhM2U-XBMZ"
      },
      "source": [
        "![rl_diagram_transparent_bg.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeneTRdyZDvy"
      },
      "source": [
        "The core element in reinforcement learning are **agent** and **environment**. You can understand RL as the following process: \n",
        "\n",
        "The agent is active in a world, which is the environment. It observe its current condition as a **state**, and is allowed to do certain **actions**. After the agent execute an action, it will arrive at a new state. At the same time, the environment will have feedback to the agent called **reward**, a numerical signal that tells how good or bad the new state is. As the figure above, agent and environment will keep doing this interaction.\n",
        "\n",
        "The goal of agent is to get as much cumulative reward as possible. Reinforcement learning is the method that agent learns to improve its behavior and achieve that goal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3H88JXkI93v"
      },
      "source": [
        "To achieve this in Python, we follow the OpenAI gym style to build the stock data into environment.\n",
        "\n",
        "state-action-reward are specified as follows:\n",
        "\n",
        "* **State s**: The state space represents an agent's perception of the market environment. Just like a human trader analyzing various information, here our agent passively observes the price data and technical indicators based on the past data. It will learn by interacting with the market environment (usually by replaying historical data).\n",
        "\n",
        "* **Action a**: The action space includes allowed actions that an agent can take at each state. For example, a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying. When an action operates multiple shares, a ∈{−k, ..., −1, 0, 1, ..., k}, e.g.. \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* **Reward function r(s, a, s′)**: Reward is an incentive for an agent to learn a better policy. For example, it can be the change of the portfolio value when taking a at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
        "\n",
        "\n",
        "**Market environment**: 30 constituent stocks of Dow Jones Industrial Average (DJIA) index. Accessed at the starting date of the testing period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKyZejI0fmp1"
      },
      "source": [
        "## Read data\n",
        "\n",
        "We first read the .csv file of our training data into dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mFCP1YEhi6oi"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train_data_single.csv')\n",
        "\n",
        "# If you are not using the data generated from part 1 of this tutorial, make sure \n",
        "# it has the columns and index in the form that could be make into the environment. \n",
        "# Then you can comment and skip the following two lines.\n",
        "train = train.set_index(train.columns[0])\n",
        "train.index.names = ['']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw95ZMicgEyi"
      },
      "source": [
        "## Construct the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WZ6-9q2gq9S"
      },
      "source": [
        "Calculate and specify the parameters we need for constructing the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T3DZPoaIm8k",
        "outputId": "4817e063-400a-416e-f8f2-4b1c4d9c8408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "11\n",
            "Stock Dimension: 1, State Space: 11\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(len(INDICATORS))\n",
        "print(state_space)\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WsOLoeNcJF8Q"
      },
      "outputs": [],
      "source": [
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 10,\n",
        "    \"initial_amount\": 100000,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    # \"print_verbosity\": 1\n",
        "}\n",
        "\n",
        "\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7We-q73jjaFQ"
      },
      "source": [
        "## Environment for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS-SHiGRJK-4",
        "outputId": "a733ecdf-d857-40f5-b399-4325c7ead299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        }
      ],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "# Part 3: Train DRL Agents\n",
        "* Here, the DRL algorithms are from **[Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/)**. It's a library that implemented popular DRL algorithms using pytorch, succeeding to its old version: Stable Baselines.\n",
        "* Users are also encouraged to try **[ElegantRL](https://github.com/AI4Finance-Foundation/ElegantRL)** and **[Ray RLlib](https://github.com/ray-project/ray)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "364PsqckttcQ"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
        "if_using_a2c = True\n",
        "if_using_ddpg = True\n",
        "if_using_ppo = True\n",
        "if_using_td3 = True\n",
        "if_using_sac = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDmqOyF9h1iz"
      },
      "source": [
        "## Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uijiWgkuh1jB"
      },
      "source": [
        "### Agent 1: A2C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUCnkn-HIbmj",
        "outputId": "2794a094-a916-448c-ead1-6e20184dde2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to results/a2c\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_a2c = agent.get_model(\"a2c\")\n",
        "\n",
        "if if_using_a2c:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/a2c'\n",
        "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_a2c.set_logger(new_logger_a2c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GVpkWGqH4-D",
        "outputId": "f29cf145-e3b5-4e59-f64d-5921462a8f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1834          |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 0             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.53         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | 0.000268      |\n",
            "|    reward             | -5.465541e-06 |\n",
            "|    std                | 1.12          |\n",
            "|    value_loss         | 5.04e-08      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1770           |\n",
            "|    iterations         | 200            |\n",
            "|    time_elapsed       | 0              |\n",
            "|    total_timesteps    | 1000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.61          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 199            |\n",
            "|    policy_loss        | 0.000883       |\n",
            "|    reward             | -1.5914961e-06 |\n",
            "|    std                | 1.21           |\n",
            "|    value_loss         | 4.96e-07       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1798         |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 0            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.68        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | 0.00035      |\n",
            "|    reward             | 0.0008227666 |\n",
            "|    std                | 1.31         |\n",
            "|    value_loss         | 8.84e-08     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1820           |\n",
            "|    iterations         | 400            |\n",
            "|    time_elapsed       | 1              |\n",
            "|    total_timesteps    | 2000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.75          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 399            |\n",
            "|    policy_loss        | -0.00103       |\n",
            "|    reward             | -0.00055244047 |\n",
            "|    std                | 1.4            |\n",
            "|    value_loss         | 2.15e-07       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1835           |\n",
            "|    iterations         | 500            |\n",
            "|    time_elapsed       | 1              |\n",
            "|    total_timesteps    | 2500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.82          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 499            |\n",
            "|    policy_loss        | 0.00229        |\n",
            "|    reward             | -2.5122668e-05 |\n",
            "|    std                | 1.5            |\n",
            "|    value_loss         | 1.29e-06       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1842          |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 1             |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.89         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | -0.026        |\n",
            "|    reward             | 0.00061023945 |\n",
            "|    std                | 1.61          |\n",
            "|    value_loss         | 0.000215      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1824          |\n",
            "|    iterations         | 700           |\n",
            "|    time_elapsed       | 1             |\n",
            "|    total_timesteps    | 3500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.96         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 699           |\n",
            "|    policy_loss        | -0.000168     |\n",
            "|    reward             | 2.1395583e-06 |\n",
            "|    std                | 1.72          |\n",
            "|    value_loss         | 9.2e-09       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1830          |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 2             |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.02         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | -0.000141     |\n",
            "|    reward             | 0.00015165111 |\n",
            "|    std                | 1.83          |\n",
            "|    value_loss         | 1.28e-08      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1833          |\n",
            "|    iterations         | 900           |\n",
            "|    time_elapsed       | 2             |\n",
            "|    total_timesteps    | 4500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.09         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 899           |\n",
            "|    policy_loss        | -0.00301      |\n",
            "|    reward             | 9.3424103e-07 |\n",
            "|    std                | 1.96          |\n",
            "|    value_loss         | 2.38e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1832          |\n",
            "|    iterations         | 1000          |\n",
            "|    time_elapsed       | 2             |\n",
            "|    total_timesteps    | 5000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.16         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 999           |\n",
            "|    policy_loss        | 0.00109       |\n",
            "|    reward             | 0.00057591364 |\n",
            "|    std                | 2.11          |\n",
            "|    value_loss         | 8e-07         |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1825         |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.23        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.0033       |\n",
            "|    reward             | 0.0017940475 |\n",
            "|    std                | 2.26         |\n",
            "|    value_loss         | 5.32e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1825         |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.3         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | -0.00139     |\n",
            "|    reward             | -1.56841e-05 |\n",
            "|    std                | 2.42         |\n",
            "|    value_loss         | 5.61e-07     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1829        |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 3           |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.37       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 0.000528    |\n",
            "|    reward             | 0.005178029 |\n",
            "|    std                | 2.59        |\n",
            "|    value_loss         | 4.24e-05    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1835      |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.43     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -0.000143 |\n",
            "|    reward             | 0.0       |\n",
            "|    std                | 2.75      |\n",
            "|    value_loss         | 3.64e-09  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1842      |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.49     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -0.000156 |\n",
            "|    reward             | 0.0       |\n",
            "|    std                | 2.93      |\n",
            "|    value_loss         | 5.82e-09  |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1848          |\n",
            "|    iterations         | 1600          |\n",
            "|    time_elapsed       | 4             |\n",
            "|    total_timesteps    | 8000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.56         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1599          |\n",
            "|    policy_loss        | 0.000381      |\n",
            "|    reward             | 0.00041648315 |\n",
            "|    std                | 3.14          |\n",
            "|    value_loss         | 6.88e-08      |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 1847     |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.63    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.00335  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 3.36     |\n",
            "|    value_loss         | 2.36e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 1844     |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.7     |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.00845  |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 3.6      |\n",
            "|    value_loss         | 1.47e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 1830     |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.77    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.00279 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 3.86     |\n",
            "|    value_loss         | 1.15e-06 |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1828         |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 5            |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.84        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -0.00252     |\n",
            "|    reward             | -0.010590265 |\n",
            "|    std                | 4.14         |\n",
            "|    value_loss         | 1.08e-06     |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 1824     |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.91    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | -0.002   |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 4.43     |\n",
            "|    value_loss         | 5.89e-07 |\n",
            "------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1825          |\n",
            "|    iterations         | 2200          |\n",
            "|    time_elapsed       | 6             |\n",
            "|    total_timesteps    | 11000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.98         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2199          |\n",
            "|    policy_loss        | 1.48e-05      |\n",
            "|    reward             | 0.00024070781 |\n",
            "|    std                | 4.74          |\n",
            "|    value_loss         | 8.14e-09      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1826          |\n",
            "|    iterations         | 2300          |\n",
            "|    time_elapsed       | 6             |\n",
            "|    total_timesteps    | 11500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.04         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2299          |\n",
            "|    policy_loss        | -0.000183     |\n",
            "|    reward             | 0.00026194597 |\n",
            "|    std                | 5.09          |\n",
            "|    value_loss         | 1.97e-08      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1829         |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.11        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | 0.0082       |\n",
            "|    reward             | 0.0012722367 |\n",
            "|    std                | 5.45         |\n",
            "|    value_loss         | 7.38e-06     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1834           |\n",
            "|    iterations         | 2500           |\n",
            "|    time_elapsed       | 6              |\n",
            "|    total_timesteps    | 12500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.18          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 2499           |\n",
            "|    policy_loss        | -0.00357       |\n",
            "|    reward             | -0.00081947015 |\n",
            "|    std                | 5.84           |\n",
            "|    value_loss         | 1.47e-06       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1838          |\n",
            "|    iterations         | 2600          |\n",
            "|    time_elapsed       | 7             |\n",
            "|    total_timesteps    | 13000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.25         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2599          |\n",
            "|    policy_loss        | -0.01         |\n",
            "|    reward             | -0.0039846497 |\n",
            "|    std                | 6.27          |\n",
            "|    value_loss         | 1.23e-05      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1841       |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 7          |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.32      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | 0.0131     |\n",
            "|    reward             | 0.03891102 |\n",
            "|    std                | 6.69       |\n",
            "|    value_loss         | 0.0018     |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1844          |\n",
            "|    iterations         | 2800          |\n",
            "|    time_elapsed       | 7             |\n",
            "|    total_timesteps    | 14000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.35         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2799          |\n",
            "|    policy_loss        | -0.00492      |\n",
            "|    reward             | -0.0007854553 |\n",
            "|    std                | 6.89          |\n",
            "|    value_loss         | 4.46e-06      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1847           |\n",
            "|    iterations         | 2900           |\n",
            "|    time_elapsed       | 7              |\n",
            "|    total_timesteps    | 14500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.4           |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 2899           |\n",
            "|    policy_loss        | 0.000905       |\n",
            "|    reward             | -5.3126674e-05 |\n",
            "|    std                | 7.23           |\n",
            "|    value_loss         | 3.38e-07       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1849         |\n",
            "|    iterations         | 3000         |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 15000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.46        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2999         |\n",
            "|    policy_loss        | -0.00167     |\n",
            "|    reward             | 0.0016743717 |\n",
            "|    std                | 7.67         |\n",
            "|    value_loss         | 3.14e-07     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1850         |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.52        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | 0.0533       |\n",
            "|    reward             | 0.0021560774 |\n",
            "|    std                | 8.16         |\n",
            "|    value_loss         | 0.000268     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1852        |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 16000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.58       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | -0.000812   |\n",
            "|    reward             | 0.005698951 |\n",
            "|    std                | 8.7         |\n",
            "|    value_loss         | 1.65e-07    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1853         |\n",
            "|    iterations         | 3300         |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 16500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.64        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3299         |\n",
            "|    policy_loss        | -0.00817     |\n",
            "|    reward             | 0.0020064975 |\n",
            "|    std                | 9.24         |\n",
            "|    value_loss         | 8.14e-06     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1854           |\n",
            "|    iterations         | 3400           |\n",
            "|    time_elapsed       | 9              |\n",
            "|    total_timesteps    | 17000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.7           |\n",
            "|    explained_variance | 5.96e-08       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 3399           |\n",
            "|    policy_loss        | 0.000699       |\n",
            "|    reward             | -2.6716264e-06 |\n",
            "|    std                | 9.74           |\n",
            "|    value_loss         | 2.77e-08       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1855          |\n",
            "|    iterations         | 3500          |\n",
            "|    time_elapsed       | 9             |\n",
            "|    total_timesteps    | 17500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.74         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3499          |\n",
            "|    policy_loss        | 0.00468       |\n",
            "|    reward             | -0.0007545556 |\n",
            "|    std                | 10.2          |\n",
            "|    value_loss         | 2.41e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1856         |\n",
            "|    iterations         | 3600         |\n",
            "|    time_elapsed       | 9            |\n",
            "|    total_timesteps    | 18000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.79        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3599         |\n",
            "|    policy_loss        | -0.0287      |\n",
            "|    reward             | -0.017785417 |\n",
            "|    std                | 10.7         |\n",
            "|    value_loss         | 0.00014      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1856         |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 9            |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.84        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | -0.107       |\n",
            "|    reward             | 0.0008224802 |\n",
            "|    std                | 11.3         |\n",
            "|    value_loss         | 0.000943     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1857          |\n",
            "|    iterations         | 3800          |\n",
            "|    time_elapsed       | 10            |\n",
            "|    total_timesteps    | 19000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.89         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3799          |\n",
            "|    policy_loss        | 0.00228       |\n",
            "|    reward             | -0.0001413365 |\n",
            "|    std                | 11.8          |\n",
            "|    value_loss         | 4.88e-07      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1859          |\n",
            "|    iterations         | 3900          |\n",
            "|    time_elapsed       | 10            |\n",
            "|    total_timesteps    | 19500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.94         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3899          |\n",
            "|    policy_loss        | -0.0102       |\n",
            "|    reward             | 0.00043298575 |\n",
            "|    std                | 12.5          |\n",
            "|    value_loss         | 9.81e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1860         |\n",
            "|    iterations         | 4000         |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 20000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.99        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3999         |\n",
            "|    policy_loss        | 0.441        |\n",
            "|    reward             | -0.026404059 |\n",
            "|    std                | 13           |\n",
            "|    value_loss         | 0.0166       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1861          |\n",
            "|    iterations         | 4100          |\n",
            "|    time_elapsed       | 11            |\n",
            "|    total_timesteps    | 20500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4            |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4099          |\n",
            "|    policy_loss        | -0.0106       |\n",
            "|    reward             | -0.0018937659 |\n",
            "|    std                | 13.2          |\n",
            "|    value_loss         | 1.07e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1861          |\n",
            "|    iterations         | 4200          |\n",
            "|    time_elapsed       | 11            |\n",
            "|    total_timesteps    | 21000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.01         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4199          |\n",
            "|    policy_loss        | -0.0435       |\n",
            "|    reward             | -0.0019953656 |\n",
            "|    std                | 13.4          |\n",
            "|    value_loss         | 0.000173      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1862        |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.04       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | -0.0765     |\n",
            "|    reward             | 0.008020604 |\n",
            "|    std                | 13.8        |\n",
            "|    value_loss         | 0.000442    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1863         |\n",
            "|    iterations         | 4400         |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 22000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.07        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4399         |\n",
            "|    policy_loss        | -0.126       |\n",
            "|    reward             | -0.006742071 |\n",
            "|    std                | 14.2         |\n",
            "|    value_loss         | 0.00083      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1860       |\n",
            "|    iterations         | 4500       |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 22500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.09      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4499       |\n",
            "|    policy_loss        | 0.00775    |\n",
            "|    reward             | 0.06241302 |\n",
            "|    std                | 14.5       |\n",
            "|    value_loss         | 0.00014    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1862        |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 12          |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.09       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | -0.82       |\n",
            "|    reward             | 0.033535827 |\n",
            "|    std                | 14.5        |\n",
            "|    value_loss         | 0.0552      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1863       |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.11      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | 0.596      |\n",
            "|    reward             | 0.36816776 |\n",
            "|    std                | 14.8       |\n",
            "|    value_loss         | 0.133      |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1864          |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.12         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | -0.0451       |\n",
            "|    reward             | 0.00033941833 |\n",
            "|    std                | 14.9          |\n",
            "|    value_loss         | 0.000135      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1865         |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.13        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | -0.00128     |\n",
            "|    reward             | -0.024802323 |\n",
            "|    std                | 15           |\n",
            "|    value_loss         | 0.000115     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1867         |\n",
            "|    iterations         | 5000         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 25000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.15        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4999         |\n",
            "|    policy_loss        | -0.0769      |\n",
            "|    reward             | -0.030937841 |\n",
            "|    std                | 15.3         |\n",
            "|    value_loss         | 0.000909     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1865        |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 13          |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.19       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | -0.177      |\n",
            "|    reward             | 0.042854372 |\n",
            "|    std                | 15.9        |\n",
            "|    value_loss         | 0.00467     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1861       |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 13         |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.19      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | -0.453     |\n",
            "|    reward             | 0.25285858 |\n",
            "|    std                | 16         |\n",
            "|    value_loss         | 0.0214     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1857       |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.22      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | 0.0206     |\n",
            "|    reward             | 0.02442578 |\n",
            "|    std                | 16.4       |\n",
            "|    value_loss         | 0.0178     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1855      |\n",
            "|    iterations         | 5400      |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.21     |\n",
            "|    explained_variance | 0.907     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5399      |\n",
            "|    policy_loss        | -1.79     |\n",
            "|    reward             | 0.6348386 |\n",
            "|    std                | 16.3      |\n",
            "|    value_loss         | 0.197     |\n",
            "-------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1851           |\n",
            "|    iterations         | 5500           |\n",
            "|    time_elapsed       | 14             |\n",
            "|    total_timesteps    | 27500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.22          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 5499           |\n",
            "|    policy_loss        | -0.021         |\n",
            "|    reward             | -0.00017115563 |\n",
            "|    std                | 16.4           |\n",
            "|    value_loss         | 2.68e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1850          |\n",
            "|    iterations         | 5600          |\n",
            "|    time_elapsed       | 15            |\n",
            "|    total_timesteps    | 28000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.24         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5599          |\n",
            "|    policy_loss        | 0.0427        |\n",
            "|    reward             | -0.0028160908 |\n",
            "|    std                | 16.7          |\n",
            "|    value_loss         | 0.00022       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1850           |\n",
            "|    iterations         | 5700           |\n",
            "|    time_elapsed       | 15             |\n",
            "|    total_timesteps    | 28500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.26          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 5699           |\n",
            "|    policy_loss        | 0.006          |\n",
            "|    reward             | -0.00011785112 |\n",
            "|    std                | 17.2           |\n",
            "|    value_loss         | 0.000182       |\n",
            "------------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1851       |\n",
            "|    iterations         | 5800       |\n",
            "|    time_elapsed       | 15         |\n",
            "|    total_timesteps    | 29000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.28      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5799       |\n",
            "|    policy_loss        | -0.133     |\n",
            "|    reward             | 0.04188934 |\n",
            "|    std                | 17.5       |\n",
            "|    value_loss         | 0.00138    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1851        |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 15          |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.3        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -1.1        |\n",
            "|    reward             | -0.08011338 |\n",
            "|    std                | 17.8        |\n",
            "|    value_loss         | 0.0772      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1852      |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.31     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -2.64     |\n",
            "|    reward             | 1.0389181 |\n",
            "|    std                | 18        |\n",
            "|    value_loss         | 1.09      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1852       |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.32      |\n",
            "|    explained_variance | -0.00217   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | -3.81      |\n",
            "|    reward             | 0.22835794 |\n",
            "|    std                | 18.1       |\n",
            "|    value_loss         | 1.27       |\n",
            "--------------------------------------\n",
            "day: 3396, episode: 10\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 324529.93\n",
            "total_reward: 224529.93\n",
            "total_cost: 1400.20\n",
            "total_trades: 3383\n",
            "Sharpe: 0.658\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1851         |\n",
            "|    iterations         | 6200         |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 31000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.33        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6199         |\n",
            "|    policy_loss        | 0.0256       |\n",
            "|    reward             | 0.0009848792 |\n",
            "|    std                | 18.3         |\n",
            "|    value_loss         | 6.96e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1852         |\n",
            "|    iterations         | 6300         |\n",
            "|    time_elapsed       | 17           |\n",
            "|    total_timesteps    | 31500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.34        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6299         |\n",
            "|    policy_loss        | -7.63e-06    |\n",
            "|    reward             | 0.0022905981 |\n",
            "|    std                | 18.6         |\n",
            "|    value_loss         | 2e-06        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1853        |\n",
            "|    iterations         | 6400        |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 32000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.37       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6399        |\n",
            "|    policy_loss        | 0.00398     |\n",
            "|    reward             | -0.00500377 |\n",
            "|    std                | 19.1        |\n",
            "|    value_loss         | 7.35e-06    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1854          |\n",
            "|    iterations         | 6500          |\n",
            "|    time_elapsed       | 17            |\n",
            "|    total_timesteps    | 32500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.4          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6499          |\n",
            "|    policy_loss        | -0.0667       |\n",
            "|    reward             | -0.0013562653 |\n",
            "|    std                | 19.7          |\n",
            "|    value_loss         | 0.000244      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1855       |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.42      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | 0.187      |\n",
            "|    reward             | 0.00625388 |\n",
            "|    std                | 20         |\n",
            "|    value_loss         | 0.00228    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1856        |\n",
            "|    iterations         | 6700        |\n",
            "|    time_elapsed       | 18          |\n",
            "|    total_timesteps    | 33500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.43       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6699        |\n",
            "|    policy_loss        | 0.262       |\n",
            "|    reward             | 0.014196731 |\n",
            "|    std                | 20.2        |\n",
            "|    value_loss         | 0.0365      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1857          |\n",
            "|    iterations         | 6800          |\n",
            "|    time_elapsed       | 18            |\n",
            "|    total_timesteps    | 34000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.44         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6799          |\n",
            "|    policy_loss        | -0.244        |\n",
            "|    reward             | -0.0004929752 |\n",
            "|    std                | 20.6          |\n",
            "|    value_loss         | 0.00286       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1858         |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.46        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | -0.000506    |\n",
            "|    reward             | 0.0035064397 |\n",
            "|    std                | 20.9         |\n",
            "|    value_loss         | 2.11e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1859          |\n",
            "|    iterations         | 7000          |\n",
            "|    time_elapsed       | 18            |\n",
            "|    total_timesteps    | 35000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.47         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6999          |\n",
            "|    policy_loss        | -0.0304       |\n",
            "|    reward             | -0.0016385945 |\n",
            "|    std                | 21.1          |\n",
            "|    value_loss         | 0.00724       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1860        |\n",
            "|    iterations         | 7100        |\n",
            "|    time_elapsed       | 19          |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.48       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7099        |\n",
            "|    policy_loss        | 0.299       |\n",
            "|    reward             | 0.037920497 |\n",
            "|    std                | 21.4        |\n",
            "|    value_loss         | 0.00883     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1861         |\n",
            "|    iterations         | 7200         |\n",
            "|    time_elapsed       | 19           |\n",
            "|    total_timesteps    | 36000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.5         |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7199         |\n",
            "|    policy_loss        | -0.000927    |\n",
            "|    reward             | 0.0012865212 |\n",
            "|    std                | 21.9         |\n",
            "|    value_loss         | 6.11e-05     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1861       |\n",
            "|    iterations         | 7300       |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 36500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.53      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7299       |\n",
            "|    policy_loss        | 0.103      |\n",
            "|    reward             | 0.01868369 |\n",
            "|    std                | 22.3       |\n",
            "|    value_loss         | 0.00277    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1862      |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.53     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | 0.817     |\n",
            "|    reward             | -0.280663 |\n",
            "|    std                | 22.4      |\n",
            "|    value_loss         | 0.165     |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1854          |\n",
            "|    iterations         | 7500          |\n",
            "|    time_elapsed       | 20            |\n",
            "|    total_timesteps    | 37500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.52         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7499          |\n",
            "|    policy_loss        | -0.0368       |\n",
            "|    reward             | 0.00041385833 |\n",
            "|    std                | 22.3          |\n",
            "|    value_loss         | 9.69e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1855         |\n",
            "|    iterations         | 7600         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 38000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.54        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7599         |\n",
            "|    policy_loss        | 0.0199       |\n",
            "|    reward             | 0.0034465394 |\n",
            "|    std                | 22.6         |\n",
            "|    value_loss         | 2.85e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1854         |\n",
            "|    iterations         | 7700         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 38500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.55        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7699         |\n",
            "|    policy_loss        | -0.122       |\n",
            "|    reward             | -0.009157657 |\n",
            "|    std                | 23           |\n",
            "|    value_loss         | 0.00115      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1852        |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 21          |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.58       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | -0.0545     |\n",
            "|    reward             | 0.018364757 |\n",
            "|    std                | 23.5        |\n",
            "|    value_loss         | 0.000263    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1853       |\n",
            "|    iterations         | 7900       |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 39500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.6       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7899       |\n",
            "|    policy_loss        | -0.659     |\n",
            "|    reward             | 0.02189733 |\n",
            "|    std                | 24.1       |\n",
            "|    value_loss         | 0.0255     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1854       |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.59      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | 0.731      |\n",
            "|    reward             | 0.07581985 |\n",
            "|    std                | 24         |\n",
            "|    value_loss         | 0.0362     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1855        |\n",
            "|    iterations         | 8100        |\n",
            "|    time_elapsed       | 21          |\n",
            "|    total_timesteps    | 40500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.61       |\n",
            "|    explained_variance | -0.43       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8099        |\n",
            "|    policy_loss        | 2.28        |\n",
            "|    reward             | -0.21173604 |\n",
            "|    std                | 24.4        |\n",
            "|    value_loss         | 0.313       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1855        |\n",
            "|    iterations         | 8200        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 41000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.62       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8199        |\n",
            "|    policy_loss        | -0.0777     |\n",
            "|    reward             | 0.007618913 |\n",
            "|    std                | 24.5        |\n",
            "|    value_loss         | 0.000341    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1856        |\n",
            "|    iterations         | 8300        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 41500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.63       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8299        |\n",
            "|    policy_loss        | -0.0292     |\n",
            "|    reward             | 0.001245973 |\n",
            "|    std                | 24.9        |\n",
            "|    value_loss         | 4.27e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1857        |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.66       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | -0.0103     |\n",
            "|    reward             | 0.005357424 |\n",
            "|    std                | 25.5        |\n",
            "|    value_loss         | 1.89e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1857        |\n",
            "|    iterations         | 8500        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 42500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.69       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8499        |\n",
            "|    policy_loss        | -0.0425     |\n",
            "|    reward             | 0.007139649 |\n",
            "|    std                | 26.3        |\n",
            "|    value_loss         | 0.000179    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1858         |\n",
            "|    iterations         | 8600         |\n",
            "|    time_elapsed       | 23           |\n",
            "|    total_timesteps    | 43000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.72        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8599         |\n",
            "|    policy_loss        | -0.0107      |\n",
            "|    reward             | -0.011232796 |\n",
            "|    std                | 27.2         |\n",
            "|    value_loss         | 0.000133     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1858        |\n",
            "|    iterations         | 8700        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 43500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.75       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8699        |\n",
            "|    policy_loss        | 0.192       |\n",
            "|    reward             | -0.02428124 |\n",
            "|    std                | 28          |\n",
            "|    value_loss         | 0.00341     |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1859      |\n",
            "|    iterations         | 8800      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -4.77     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8799      |\n",
            "|    policy_loss        | 0.000933  |\n",
            "|    reward             | 0.0       |\n",
            "|    std                | 28.6      |\n",
            "|    value_loss         | 1.05e-06  |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1859          |\n",
            "|    iterations         | 8900          |\n",
            "|    time_elapsed       | 23            |\n",
            "|    total_timesteps    | 44500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.8          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8899          |\n",
            "|    policy_loss        | -0.000916     |\n",
            "|    reward             | 0.00054104155 |\n",
            "|    std                | 29.5          |\n",
            "|    value_loss         | 3.93e-08      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1858          |\n",
            "|    iterations         | 9000          |\n",
            "|    time_elapsed       | 24            |\n",
            "|    total_timesteps    | 45000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.85         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8999          |\n",
            "|    policy_loss        | 0.0266        |\n",
            "|    reward             | 0.00056440727 |\n",
            "|    std                | 30.8          |\n",
            "|    value_loss         | 3.82e-05      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1859           |\n",
            "|    iterations         | 9100           |\n",
            "|    time_elapsed       | 24             |\n",
            "|    total_timesteps    | 45500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.9           |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9099           |\n",
            "|    policy_loss        | 0.00309        |\n",
            "|    reward             | -0.00034277275 |\n",
            "|    std                | 32.5           |\n",
            "|    value_loss         | 2.03e-06       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1859           |\n",
            "|    iterations         | 9200           |\n",
            "|    time_elapsed       | 24             |\n",
            "|    total_timesteps    | 46000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.96          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9199           |\n",
            "|    policy_loss        | -0.00985       |\n",
            "|    reward             | -0.00021611928 |\n",
            "|    std                | 34.5           |\n",
            "|    value_loss         | 4.31e-06       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1859          |\n",
            "|    iterations         | 9300          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 46500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5.02         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9299          |\n",
            "|    policy_loss        | 0.00851       |\n",
            "|    reward             | -0.0023122965 |\n",
            "|    std                | 36.8          |\n",
            "|    value_loss         | 3.43e-06      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1859        |\n",
            "|    iterations         | 9400        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 47000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.08       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9399        |\n",
            "|    policy_loss        | 0.384       |\n",
            "|    reward             | -0.01904353 |\n",
            "|    std                | 39          |\n",
            "|    value_loss         | 0.00985     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1859        |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.08       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | -0.615      |\n",
            "|    reward             | 0.017422525 |\n",
            "|    std                | 38.9        |\n",
            "|    value_loss         | 0.0266      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1859       |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -5.1       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | -0.00614   |\n",
            "|    reward             | 0.00257642 |\n",
            "|    std                | 39.6       |\n",
            "|    value_loss         | 1.54e-06   |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 1859     |\n",
            "|    iterations         | 9700     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 48500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.12    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9699     |\n",
            "|    policy_loss        | -0.00213 |\n",
            "|    reward             | 0.0      |\n",
            "|    std                | 40.6     |\n",
            "|    value_loss         | 2.14e-07 |\n",
            "------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1860          |\n",
            "|    iterations         | 9800          |\n",
            "|    time_elapsed       | 26            |\n",
            "|    total_timesteps    | 49000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5.16         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9799          |\n",
            "|    policy_loss        | -0.00511      |\n",
            "|    reward             | -0.0065847547 |\n",
            "|    std                | 42.1          |\n",
            "|    value_loss         | 2.41e-06      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1861           |\n",
            "|    iterations         | 9900           |\n",
            "|    time_elapsed       | 26             |\n",
            "|    total_timesteps    | 49500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -5.2           |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9899           |\n",
            "|    policy_loss        | 0.12           |\n",
            "|    reward             | -0.00018662334 |\n",
            "|    std                | 43.8           |\n",
            "|    value_loss         | 0.00171        |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1861        |\n",
            "|    iterations         | 10000       |\n",
            "|    time_elapsed       | 26          |\n",
            "|    total_timesteps    | 50000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.23       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9999        |\n",
            "|    policy_loss        | -0.406      |\n",
            "|    reward             | -0.03307446 |\n",
            "|    std                | 45.3        |\n",
            "|    value_loss         | 0.00757     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1861        |\n",
            "|    iterations         | 10100       |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 50500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.24       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10099       |\n",
            "|    policy_loss        | 0.655       |\n",
            "|    reward             | -0.23350635 |\n",
            "|    std                | 45.8        |\n",
            "|    value_loss         | 0.0502      |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1862           |\n",
            "|    iterations         | 10200          |\n",
            "|    time_elapsed       | 27             |\n",
            "|    total_timesteps    | 51000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -5.26          |\n",
            "|    explained_variance | 5.96e-08       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 10199          |\n",
            "|    policy_loss        | -0.0793        |\n",
            "|    reward             | -2.5128884e-06 |\n",
            "|    std                | 46.8           |\n",
            "|    value_loss         | 0.000292       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1862         |\n",
            "|    iterations         | 10300        |\n",
            "|    time_elapsed       | 27           |\n",
            "|    total_timesteps    | 51500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.28        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10299        |\n",
            "|    policy_loss        | -0.0489      |\n",
            "|    reward             | 0.0058382475 |\n",
            "|    std                | 47.7         |\n",
            "|    value_loss         | 0.000158     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1862         |\n",
            "|    iterations         | 10400        |\n",
            "|    time_elapsed       | 27           |\n",
            "|    total_timesteps    | 52000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.32        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10399        |\n",
            "|    policy_loss        | -0.0818      |\n",
            "|    reward             | -0.004458662 |\n",
            "|    std                | 49.4         |\n",
            "|    value_loss         | 0.000285     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1862         |\n",
            "|    iterations         | 10500        |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 52500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.34        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10499        |\n",
            "|    policy_loss        | 0.233        |\n",
            "|    reward             | -0.012545505 |\n",
            "|    std                | 50.4         |\n",
            "|    value_loss         | 0.00348      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1863         |\n",
            "|    iterations         | 10600        |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 53000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10599        |\n",
            "|    policy_loss        | 0.289        |\n",
            "|    reward             | -0.003929141 |\n",
            "|    std                | 52.2         |\n",
            "|    value_loss         | 0.00378      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1863         |\n",
            "|    iterations         | 10700        |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 53500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.41        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10699        |\n",
            "|    policy_loss        | 0.644        |\n",
            "|    reward             | -0.016838571 |\n",
            "|    std                | 53.9         |\n",
            "|    value_loss         | 0.0206       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1864        |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 28          |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.39       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | -3.95       |\n",
            "|    reward             | 0.019722406 |\n",
            "|    std                | 53.1        |\n",
            "|    value_loss         | 0.958       |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1861           |\n",
            "|    iterations         | 10900          |\n",
            "|    time_elapsed       | 29             |\n",
            "|    total_timesteps    | 54500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -5.39          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 10899          |\n",
            "|    policy_loss        | -0.0643        |\n",
            "|    reward             | -2.8951423e-05 |\n",
            "|    std                | 53             |\n",
            "|    value_loss         | 0.00015        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1862           |\n",
            "|    iterations         | 11000          |\n",
            "|    time_elapsed       | 29             |\n",
            "|    total_timesteps    | 55000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -5.4           |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 10999          |\n",
            "|    policy_loss        | 0.0296         |\n",
            "|    reward             | -0.00062356505 |\n",
            "|    std                | 53.7           |\n",
            "|    value_loss         | 3.86e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1862         |\n",
            "|    iterations         | 11100        |\n",
            "|    time_elapsed       | 29           |\n",
            "|    total_timesteps    | 55500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.42        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 11099        |\n",
            "|    policy_loss        | -0.0154      |\n",
            "|    reward             | 0.0030009558 |\n",
            "|    std                | 54.8         |\n",
            "|    value_loss         | 1.72e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1862        |\n",
            "|    iterations         | 11200       |\n",
            "|    time_elapsed       | 30          |\n",
            "|    total_timesteps    | 56000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.45       |\n",
            "|    explained_variance | 2.38e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11199       |\n",
            "|    policy_loss        | 0.2         |\n",
            "|    reward             | -0.06469757 |\n",
            "|    std                | 56.2        |\n",
            "|    value_loss         | 0.00198     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1862        |\n",
            "|    iterations         | 11300       |\n",
            "|    time_elapsed       | 30          |\n",
            "|    total_timesteps    | 56500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.47       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11299       |\n",
            "|    policy_loss        | 0.122       |\n",
            "|    reward             | 0.012966369 |\n",
            "|    std                | 57.4        |\n",
            "|    value_loss         | 0.000754    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1863        |\n",
            "|    iterations         | 11400       |\n",
            "|    time_elapsed       | 30          |\n",
            "|    total_timesteps    | 57000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.5        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11399       |\n",
            "|    policy_loss        | 0.331       |\n",
            "|    reward             | 0.039009646 |\n",
            "|    std                | 59.4        |\n",
            "|    value_loss         | 0.00625     |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 1863      |\n",
            "|    iterations         | 11500     |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 57500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.51     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 11499     |\n",
            "|    policy_loss        | 1.07      |\n",
            "|    reward             | 0.2860639 |\n",
            "|    std                | 60        |\n",
            "|    value_loss         | 0.0425    |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1853          |\n",
            "|    iterations         | 11600         |\n",
            "|    time_elapsed       | 31            |\n",
            "|    total_timesteps    | 58000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5.52         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 11599         |\n",
            "|    policy_loss        | 0.00262       |\n",
            "|    reward             | -0.0004768637 |\n",
            "|    std                | 60.3          |\n",
            "|    value_loss         | 8.44e-07      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1853        |\n",
            "|    iterations         | 11700       |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 58500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.53       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11699       |\n",
            "|    policy_loss        | -0.0588     |\n",
            "|    reward             | 0.009064452 |\n",
            "|    std                | 61.2        |\n",
            "|    value_loss         | 0.000244    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1853        |\n",
            "|    iterations         | 11800       |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 59000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.56       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11799       |\n",
            "|    policy_loss        | -0.156      |\n",
            "|    reward             | 0.010263682 |\n",
            "|    std                | 62.6        |\n",
            "|    value_loss         | 0.000856    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1854         |\n",
            "|    iterations         | 11900        |\n",
            "|    time_elapsed       | 32           |\n",
            "|    total_timesteps    | 59500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.58        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 11899        |\n",
            "|    policy_loss        | -0.165       |\n",
            "|    reward             | 0.0143496115 |\n",
            "|    std                | 64.2         |\n",
            "|    value_loss         | 0.00161      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1854        |\n",
            "|    iterations         | 12000       |\n",
            "|    time_elapsed       | 32          |\n",
            "|    total_timesteps    | 60000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.6        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 11999       |\n",
            "|    policy_loss        | -0.346      |\n",
            "|    reward             | 0.082549304 |\n",
            "|    std                | 65.8        |\n",
            "|    value_loss         | 0.00564     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1854       |\n",
            "|    iterations         | 12100      |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 60500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -5.62      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12099      |\n",
            "|    policy_loss        | 0.25       |\n",
            "|    reward             | 0.14212137 |\n",
            "|    std                | 67.2       |\n",
            "|    value_loss         | 0.00431    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1854         |\n",
            "|    iterations         | 12200        |\n",
            "|    time_elapsed       | 32           |\n",
            "|    total_timesteps    | 61000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.65        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 12199        |\n",
            "|    policy_loss        | 3.42         |\n",
            "|    reward             | -0.066785164 |\n",
            "|    std                | 68.7         |\n",
            "|    value_loss         | 0.462        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1855         |\n",
            "|    iterations         | 12300        |\n",
            "|    time_elapsed       | 33           |\n",
            "|    total_timesteps    | 61500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.66        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 12299        |\n",
            "|    policy_loss        | -0.0112      |\n",
            "|    reward             | 0.0014253939 |\n",
            "|    std                | 69.4         |\n",
            "|    value_loss         | 1.25e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1855         |\n",
            "|    iterations         | 12400        |\n",
            "|    time_elapsed       | 33           |\n",
            "|    total_timesteps    | 62000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.67        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 12399        |\n",
            "|    policy_loss        | -0.0736      |\n",
            "|    reward             | 0.0067631374 |\n",
            "|    std                | 70.5         |\n",
            "|    value_loss         | 0.000201     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1855        |\n",
            "|    iterations         | 12500       |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 62500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.7        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12499       |\n",
            "|    policy_loss        | 0.0362      |\n",
            "|    reward             | 0.004131796 |\n",
            "|    std                | 72.5        |\n",
            "|    value_loss         | 7.47e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1856        |\n",
            "|    iterations         | 12600       |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 63000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.72       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12599       |\n",
            "|    policy_loss        | -0.00201    |\n",
            "|    reward             | 0.046333365 |\n",
            "|    std                | 74          |\n",
            "|    value_loss         | 6.08e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1856        |\n",
            "|    iterations         | 12700       |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 63500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.76       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12699       |\n",
            "|    policy_loss        | 1.04        |\n",
            "|    reward             | 0.054529794 |\n",
            "|    std                | 76.4        |\n",
            "|    value_loss         | 0.0474      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1856       |\n",
            "|    iterations         | 12800      |\n",
            "|    time_elapsed       | 34         |\n",
            "|    total_timesteps    | 64000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -5.77      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 12799      |\n",
            "|    policy_loss        | 0.934      |\n",
            "|    reward             | 0.07478096 |\n",
            "|    std                | 77.8       |\n",
            "|    value_loss         | 0.035      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1857        |\n",
            "|    iterations         | 12900       |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 64500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.77       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 12899       |\n",
            "|    policy_loss        | -2.16       |\n",
            "|    reward             | -0.45914495 |\n",
            "|    std                | 77.5        |\n",
            "|    value_loss         | 0.152       |\n",
            "---------------------------------------\n",
            "day: 3396, episode: 20\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 204871.86\n",
            "total_reward: 104871.86\n",
            "total_cost: 1420.73\n",
            "total_trades: 3391\n",
            "Sharpe: 0.663\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1857          |\n",
            "|    iterations         | 13000         |\n",
            "|    time_elapsed       | 34            |\n",
            "|    total_timesteps    | 65000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5.78         |\n",
            "|    explained_variance | 1.79e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 12999         |\n",
            "|    policy_loss        | 0.00305       |\n",
            "|    reward             | -0.0002720705 |\n",
            "|    std                | 78.6          |\n",
            "|    value_loss         | 9.81e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1858          |\n",
            "|    iterations         | 13100         |\n",
            "|    time_elapsed       | 35            |\n",
            "|    total_timesteps    | 65500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5.81         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 13099         |\n",
            "|    policy_loss        | -0.028        |\n",
            "|    reward             | -0.0015461482 |\n",
            "|    std                | 80.5          |\n",
            "|    value_loss         | 3.74e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1858         |\n",
            "|    iterations         | 13200        |\n",
            "|    time_elapsed       | 35           |\n",
            "|    total_timesteps    | 66000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.84        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 13199        |\n",
            "|    policy_loss        | 0.0606       |\n",
            "|    reward             | -0.010874387 |\n",
            "|    std                | 83.2         |\n",
            "|    value_loss         | 0.000124     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1859         |\n",
            "|    iterations         | 13300        |\n",
            "|    time_elapsed       | 35           |\n",
            "|    total_timesteps    | 66500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.88        |\n",
            "|    explained_variance | 2.38e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 13299        |\n",
            "|    policy_loss        | -0.0107      |\n",
            "|    reward             | 0.0019438365 |\n",
            "|    std                | 86.3         |\n",
            "|    value_loss         | 2.96e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1859        |\n",
            "|    iterations         | 13400       |\n",
            "|    time_elapsed       | 36          |\n",
            "|    total_timesteps    | 67000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.91       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13399       |\n",
            "|    policy_loss        | 0.173       |\n",
            "|    reward             | -0.03345533 |\n",
            "|    std                | 89.7        |\n",
            "|    value_loss         | 0.00111     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1859       |\n",
            "|    iterations         | 13500      |\n",
            "|    time_elapsed       | 36         |\n",
            "|    total_timesteps    | 67500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -5.92      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 13499      |\n",
            "|    policy_loss        | -1.14      |\n",
            "|    reward             | 0.08130352 |\n",
            "|    std                | 90.3       |\n",
            "|    value_loss         | 0.067      |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1859          |\n",
            "|    iterations         | 13600         |\n",
            "|    time_elapsed       | 36            |\n",
            "|    total_timesteps    | 68000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5.93         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 13599         |\n",
            "|    policy_loss        | -0.159        |\n",
            "|    reward             | 0.00028258175 |\n",
            "|    std                | 90.7          |\n",
            "|    value_loss         | 0.000909      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1859        |\n",
            "|    iterations         | 13700       |\n",
            "|    time_elapsed       | 36          |\n",
            "|    total_timesteps    | 68500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.94       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13699       |\n",
            "|    policy_loss        | -0.082      |\n",
            "|    reward             | 0.007172453 |\n",
            "|    std                | 91.7        |\n",
            "|    value_loss         | 0.000308    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1859          |\n",
            "|    iterations         | 13800         |\n",
            "|    time_elapsed       | 37            |\n",
            "|    total_timesteps    | 69000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5.96         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 13799         |\n",
            "|    policy_loss        | 0.00128       |\n",
            "|    reward             | 0.00020552588 |\n",
            "|    std                | 93.5          |\n",
            "|    value_loss         | 4.36e-07      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1859        |\n",
            "|    iterations         | 13900       |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 69500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.98       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13899       |\n",
            "|    policy_loss        | -0.241      |\n",
            "|    reward             | 0.022482218 |\n",
            "|    std                | 95.9        |\n",
            "|    value_loss         | 0.00197     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1859        |\n",
            "|    iterations         | 14000       |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 70000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.01       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 13999       |\n",
            "|    policy_loss        | 0.057       |\n",
            "|    reward             | 0.005260149 |\n",
            "|    std                | 98.3        |\n",
            "|    value_loss         | 0.000197    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1859        |\n",
            "|    iterations         | 14100       |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 70500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.04       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14099       |\n",
            "|    policy_loss        | -0.0107     |\n",
            "|    reward             | -0.01890517 |\n",
            "|    std                | 101         |\n",
            "|    value_loss         | 0.000147    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1860        |\n",
            "|    iterations         | 14200       |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 71000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.05       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14199       |\n",
            "|    policy_loss        | -1.77       |\n",
            "|    reward             | -0.15862952 |\n",
            "|    std                | 103         |\n",
            "|    value_loss         | 0.0953      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1859          |\n",
            "|    iterations         | 14300         |\n",
            "|    time_elapsed       | 38            |\n",
            "|    total_timesteps    | 71500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -6.07         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 14299         |\n",
            "|    policy_loss        | -0.00527      |\n",
            "|    reward             | -0.0002457912 |\n",
            "|    std                | 104           |\n",
            "|    value_loss         | 1.03e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1860          |\n",
            "|    iterations         | 14400         |\n",
            "|    time_elapsed       | 38            |\n",
            "|    total_timesteps    | 72000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -6.08         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 14399         |\n",
            "|    policy_loss        | 0.0211        |\n",
            "|    reward             | -0.0022226716 |\n",
            "|    std                | 106           |\n",
            "|    value_loss         | 1.37e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1860         |\n",
            "|    iterations         | 14500        |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 72500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.11        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 14499        |\n",
            "|    policy_loss        | -0.0232      |\n",
            "|    reward             | 0.0021144962 |\n",
            "|    std                | 109          |\n",
            "|    value_loss         | 1.61e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1860        |\n",
            "|    iterations         | 14600       |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 73000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.15       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14599       |\n",
            "|    policy_loss        | -0.276      |\n",
            "|    reward             | 0.020650286 |\n",
            "|    std                | 114         |\n",
            "|    value_loss         | 0.00337     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1861        |\n",
            "|    iterations         | 14700       |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 73500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.18       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14699       |\n",
            "|    policy_loss        | -0.253      |\n",
            "|    reward             | 0.030076187 |\n",
            "|    std                | 117         |\n",
            "|    value_loss         | 0.00235     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1861        |\n",
            "|    iterations         | 14800       |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 74000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.22       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14799       |\n",
            "|    policy_loss        | 0.0586      |\n",
            "|    reward             | -0.10648983 |\n",
            "|    std                | 122         |\n",
            "|    value_loss         | 0.00282     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1861        |\n",
            "|    iterations         | 14900       |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 74500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.22       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 14899       |\n",
            "|    policy_loss        | -1.4        |\n",
            "|    reward             | -0.22202365 |\n",
            "|    std                | 121         |\n",
            "|    value_loss         | 0.171       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1862         |\n",
            "|    iterations         | 15000        |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 75000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.22        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 14999        |\n",
            "|    policy_loss        | -0.078       |\n",
            "|    reward             | 0.0044979025 |\n",
            "|    std                | 122          |\n",
            "|    value_loss         | 0.00016      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1862        |\n",
            "|    iterations         | 15100       |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 75500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.24       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15099       |\n",
            "|    policy_loss        | 0.0586      |\n",
            "|    reward             | 0.008760798 |\n",
            "|    std                | 124         |\n",
            "|    value_loss         | 0.000155    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1856        |\n",
            "|    iterations         | 15200       |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 76000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.26       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15199       |\n",
            "|    policy_loss        | -0.088      |\n",
            "|    reward             | 0.012716897 |\n",
            "|    std                | 127         |\n",
            "|    value_loss         | 0.000307    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1855       |\n",
            "|    iterations         | 15300      |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 76500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -6.3       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15299      |\n",
            "|    policy_loss        | -0.142     |\n",
            "|    reward             | 0.00562408 |\n",
            "|    std                | 132        |\n",
            "|    value_loss         | 0.000597   |\n",
            "--------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 1854           |\n",
            "|    iterations         | 15400          |\n",
            "|    time_elapsed       | 41             |\n",
            "|    total_timesteps    | 77000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -6.32          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 15399          |\n",
            "|    policy_loss        | -0.777         |\n",
            "|    reward             | -0.00062100583 |\n",
            "|    std                | 134            |\n",
            "|    value_loss         | 0.00962        |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1847        |\n",
            "|    iterations         | 15500       |\n",
            "|    time_elapsed       | 41          |\n",
            "|    total_timesteps    | 77500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.34       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15499       |\n",
            "|    policy_loss        | -0.221      |\n",
            "|    reward             | 0.045996588 |\n",
            "|    std                | 138         |\n",
            "|    value_loss         | 0.00314     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1842       |\n",
            "|    iterations         | 15600      |\n",
            "|    time_elapsed       | 42         |\n",
            "|    total_timesteps    | 78000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -6.35      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 15599      |\n",
            "|    policy_loss        | 3.39       |\n",
            "|    reward             | 0.38475236 |\n",
            "|    std                | 139        |\n",
            "|    value_loss         | 0.257      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1841         |\n",
            "|    iterations         | 15700        |\n",
            "|    time_elapsed       | 42           |\n",
            "|    total_timesteps    | 78500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 15699        |\n",
            "|    policy_loss        | 0.07         |\n",
            "|    reward             | 0.0058890376 |\n",
            "|    std                | 141          |\n",
            "|    value_loss         | 0.000153     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1840          |\n",
            "|    iterations         | 15800         |\n",
            "|    time_elapsed       | 42            |\n",
            "|    total_timesteps    | 79000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -6.39         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 15799         |\n",
            "|    policy_loss        | -0.0348       |\n",
            "|    reward             | -0.0015869117 |\n",
            "|    std                | 144           |\n",
            "|    value_loss         | 0.000386      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1839         |\n",
            "|    iterations         | 15900        |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 79500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.4         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 15899        |\n",
            "|    policy_loss        | 0.151        |\n",
            "|    reward             | -0.034368843 |\n",
            "|    std                | 146          |\n",
            "|    value_loss         | 0.000809     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1840        |\n",
            "|    iterations         | 16000       |\n",
            "|    time_elapsed       | 43          |\n",
            "|    total_timesteps    | 80000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.42       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 15999       |\n",
            "|    policy_loss        | 0.187       |\n",
            "|    reward             | 0.011198414 |\n",
            "|    std                | 149         |\n",
            "|    value_loss         | 0.00277     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1840       |\n",
            "|    iterations         | 16100      |\n",
            "|    time_elapsed       | 43         |\n",
            "|    total_timesteps    | 80500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -6.44      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16099      |\n",
            "|    policy_loss        | 0.132      |\n",
            "|    reward             | 0.13653517 |\n",
            "|    std                | 151        |\n",
            "|    value_loss         | 0.00106    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1839        |\n",
            "|    iterations         | 16200       |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 81000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.44       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16199       |\n",
            "|    policy_loss        | 2.57        |\n",
            "|    reward             | 0.007405667 |\n",
            "|    std                | 151         |\n",
            "|    value_loss         | 0.176       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1840       |\n",
            "|    iterations         | 16300      |\n",
            "|    time_elapsed       | 44         |\n",
            "|    total_timesteps    | 81500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -6.43      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 16299      |\n",
            "|    policy_loss        | -6.48      |\n",
            "|    reward             | 0.05344847 |\n",
            "|    std                | 150        |\n",
            "|    value_loss         | 2.34       |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1840          |\n",
            "|    iterations         | 16400         |\n",
            "|    time_elapsed       | 44            |\n",
            "|    total_timesteps    | 82000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -6.44         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 16399         |\n",
            "|    policy_loss        | -0.0106       |\n",
            "|    reward             | -0.0059249075 |\n",
            "|    std                | 152           |\n",
            "|    value_loss         | 1.13e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1841         |\n",
            "|    iterations         | 16500        |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 82500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.45        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 16499        |\n",
            "|    policy_loss        | -0.2         |\n",
            "|    reward             | -0.010390718 |\n",
            "|    std                | 153          |\n",
            "|    value_loss         | 0.00143      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1842        |\n",
            "|    iterations         | 16600       |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 83000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.47       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16599       |\n",
            "|    policy_loss        | 0.11        |\n",
            "|    reward             | 0.008836767 |\n",
            "|    std                | 156         |\n",
            "|    value_loss         | 0.00078     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1842        |\n",
            "|    iterations         | 16700       |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 83500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.47       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16699       |\n",
            "|    policy_loss        | 0.172       |\n",
            "|    reward             | -0.06111489 |\n",
            "|    std                | 156         |\n",
            "|    value_loss         | 0.00072     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1843        |\n",
            "|    iterations         | 16800       |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 84000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.49       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16799       |\n",
            "|    policy_loss        | -0.235      |\n",
            "|    reward             | -0.07962539 |\n",
            "|    std                | 159         |\n",
            "|    value_loss         | 0.00488     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1844        |\n",
            "|    iterations         | 16900       |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 84500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.5        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 16899       |\n",
            "|    policy_loss        | 0.4         |\n",
            "|    reward             | -0.16865472 |\n",
            "|    std                | 161         |\n",
            "|    value_loss         | 0.238       |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1844          |\n",
            "|    iterations         | 17000         |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 85000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -6.51         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 16999         |\n",
            "|    policy_loss        | -0.283        |\n",
            "|    reward             | -4.146965e-05 |\n",
            "|    std                | 162           |\n",
            "|    value_loss         | 0.00252       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1844         |\n",
            "|    iterations         | 17100        |\n",
            "|    time_elapsed       | 46           |\n",
            "|    total_timesteps    | 85500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.52        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 17099        |\n",
            "|    policy_loss        | -0.0681      |\n",
            "|    reward             | -0.006785705 |\n",
            "|    std                | 164          |\n",
            "|    value_loss         | 0.000143     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1844          |\n",
            "|    iterations         | 17200         |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 86000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -6.54         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 17199         |\n",
            "|    policy_loss        | -0.0468       |\n",
            "|    reward             | -0.0071712825 |\n",
            "|    std                | 168           |\n",
            "|    value_loss         | 9.77e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1845         |\n",
            "|    iterations         | 17300        |\n",
            "|    time_elapsed       | 46           |\n",
            "|    total_timesteps    | 86500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.57        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 17299        |\n",
            "|    policy_loss        | -0.0972      |\n",
            "|    reward             | -0.006366878 |\n",
            "|    std                | 172          |\n",
            "|    value_loss         | 0.000868     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1845          |\n",
            "|    iterations         | 17400         |\n",
            "|    time_elapsed       | 47            |\n",
            "|    total_timesteps    | 87000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -6.59         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 17399         |\n",
            "|    policy_loss        | -0.0871       |\n",
            "|    reward             | -0.0051242756 |\n",
            "|    std                | 175           |\n",
            "|    value_loss         | 0.000324      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1846         |\n",
            "|    iterations         | 17500        |\n",
            "|    time_elapsed       | 47           |\n",
            "|    total_timesteps    | 87500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.61        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 17499        |\n",
            "|    policy_loss        | 0.838        |\n",
            "|    reward             | 0.0040526837 |\n",
            "|    std                | 179          |\n",
            "|    value_loss         | 0.0167       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1846         |\n",
            "|    iterations         | 17600        |\n",
            "|    time_elapsed       | 47           |\n",
            "|    total_timesteps    | 88000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.62        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 17599        |\n",
            "|    policy_loss        | 2.01         |\n",
            "|    reward             | -0.074809074 |\n",
            "|    std                | 181          |\n",
            "|    value_loss         | 0.103        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1846          |\n",
            "|    iterations         | 17700         |\n",
            "|    time_elapsed       | 47            |\n",
            "|    total_timesteps    | 88500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -6.63         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 17699         |\n",
            "|    policy_loss        | -0.0272       |\n",
            "|    reward             | 0.00015656464 |\n",
            "|    std                | 183           |\n",
            "|    value_loss         | 2.28e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1847         |\n",
            "|    iterations         | 17800        |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 89000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.64        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 17799        |\n",
            "|    policy_loss        | -0.0422      |\n",
            "|    reward             | 0.0011786501 |\n",
            "|    std                | 186          |\n",
            "|    value_loss         | 4.2e-05      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1848         |\n",
            "|    iterations         | 17900        |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 89500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.67        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 17899        |\n",
            "|    policy_loss        | -0.0156      |\n",
            "|    reward             | 0.0014674648 |\n",
            "|    std                | 191          |\n",
            "|    value_loss         | 7.66e-06     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1848       |\n",
            "|    iterations         | 18000      |\n",
            "|    time_elapsed       | 48         |\n",
            "|    total_timesteps    | 90000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -6.71      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 17999      |\n",
            "|    policy_loss        | 0.144      |\n",
            "|    reward             | 0.03396062 |\n",
            "|    std                | 198        |\n",
            "|    value_loss         | 0.00131    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1848        |\n",
            "|    iterations         | 18100       |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 90500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.75       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18099       |\n",
            "|    policy_loss        | -0.302      |\n",
            "|    reward             | 0.025490645 |\n",
            "|    std                | 208         |\n",
            "|    value_loss         | 0.00309     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1849       |\n",
            "|    iterations         | 18200      |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 91000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -6.77      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18199      |\n",
            "|    policy_loss        | 0.341      |\n",
            "|    reward             | -0.1734278 |\n",
            "|    std                | 211        |\n",
            "|    value_loss         | 0.00617    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1845       |\n",
            "|    iterations         | 18300      |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 91500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -6.79      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18299      |\n",
            "|    policy_loss        | -0.703     |\n",
            "|    reward             | -0.3060363 |\n",
            "|    std                | 215        |\n",
            "|    value_loss         | 0.0154     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1844         |\n",
            "|    iterations         | 18400        |\n",
            "|    time_elapsed       | 49           |\n",
            "|    total_timesteps    | 92000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.82        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 18399        |\n",
            "|    policy_loss        | -0.0266      |\n",
            "|    reward             | 0.0025141903 |\n",
            "|    std                | 221          |\n",
            "|    value_loss         | 2.29e-05     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1845       |\n",
            "|    iterations         | 18500      |\n",
            "|    time_elapsed       | 50         |\n",
            "|    total_timesteps    | 92500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -6.84      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 18499      |\n",
            "|    policy_loss        | 0.0192     |\n",
            "|    reward             | 0.00682171 |\n",
            "|    std                | 225        |\n",
            "|    value_loss         | 1.66e-05   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1844         |\n",
            "|    iterations         | 18600        |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 93000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.86        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 18599        |\n",
            "|    policy_loss        | -0.303       |\n",
            "|    reward             | 0.0042383987 |\n",
            "|    std                | 232          |\n",
            "|    value_loss         | 0.00264      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1845        |\n",
            "|    iterations         | 18700       |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 93500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.9        |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18699       |\n",
            "|    policy_loss        | 0.272       |\n",
            "|    reward             | -0.01528766 |\n",
            "|    std                | 239         |\n",
            "|    value_loss         | 0.00279     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1845         |\n",
            "|    iterations         | 18800        |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 94000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -6.92        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 18799        |\n",
            "|    policy_loss        | 0.164        |\n",
            "|    reward             | -0.028898323 |\n",
            "|    std                | 245          |\n",
            "|    value_loss         | 0.000751     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1845        |\n",
            "|    iterations         | 18900       |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 94500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.94       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18899       |\n",
            "|    policy_loss        | 0.188       |\n",
            "|    reward             | 0.011660674 |\n",
            "|    std                | 251         |\n",
            "|    value_loss         | 0.00348     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1846        |\n",
            "|    iterations         | 19000       |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 95000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -6.97       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 18999       |\n",
            "|    policy_loss        | -3.17       |\n",
            "|    reward             | -0.21256775 |\n",
            "|    std                | 258         |\n",
            "|    value_loss         | 0.225       |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1846          |\n",
            "|    iterations         | 19100         |\n",
            "|    time_elapsed       | 51            |\n",
            "|    total_timesteps    | 95500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -6.98         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 19099         |\n",
            "|    policy_loss        | 0.0404        |\n",
            "|    reward             | 0.00086406356 |\n",
            "|    std                | 261           |\n",
            "|    value_loss         | 5.27e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1846         |\n",
            "|    iterations         | 19200        |\n",
            "|    time_elapsed       | 51           |\n",
            "|    total_timesteps    | 96000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.01        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 19199        |\n",
            "|    policy_loss        | -0.0977      |\n",
            "|    reward             | -0.005382921 |\n",
            "|    std                | 267          |\n",
            "|    value_loss         | 0.000215     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 1846        |\n",
            "|    iterations         | 19300       |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 96500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -7.04       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 19299       |\n",
            "|    policy_loss        | -0.0244     |\n",
            "|    reward             | 0.006421988 |\n",
            "|    std                | 276         |\n",
            "|    value_loss         | 7.24e-05    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1847       |\n",
            "|    iterations         | 19400      |\n",
            "|    time_elapsed       | 52         |\n",
            "|    total_timesteps    | 97000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.07      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19399      |\n",
            "|    policy_loss        | -0.0416    |\n",
            "|    reward             | 0.02542522 |\n",
            "|    std                | 286        |\n",
            "|    value_loss         | 0.000304   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1847         |\n",
            "|    iterations         | 19500        |\n",
            "|    time_elapsed       | 52           |\n",
            "|    total_timesteps    | 97500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.09        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 19499        |\n",
            "|    policy_loss        | -0.383       |\n",
            "|    reward             | -0.010504811 |\n",
            "|    std                | 290          |\n",
            "|    value_loss         | 0.00318      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1848         |\n",
            "|    iterations         | 19600        |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 98000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.09        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 19599        |\n",
            "|    policy_loss        | -0.655       |\n",
            "|    reward             | 0.0036856877 |\n",
            "|    std                | 290          |\n",
            "|    value_loss         | 0.0781       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 1848       |\n",
            "|    iterations         | 19700      |\n",
            "|    time_elapsed       | 53         |\n",
            "|    total_timesteps    | 98500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -7.08      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 19699      |\n",
            "|    policy_loss        | -2.63      |\n",
            "|    reward             | -0.6145752 |\n",
            "|    std                | 287        |\n",
            "|    value_loss         | 0.181      |\n",
            "--------------------------------------\n",
            "day: 3396, episode: 30\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 215083.50\n",
            "total_reward: 115083.50\n",
            "total_cost: 1427.23\n",
            "total_trades: 3395\n",
            "Sharpe: 0.575\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1848         |\n",
            "|    iterations         | 19800        |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 99000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.09        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 19799        |\n",
            "|    policy_loss        | 0.00202      |\n",
            "|    reward             | 0.0015989469 |\n",
            "|    std                | 290          |\n",
            "|    value_loss         | 2.29e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 1849         |\n",
            "|    iterations         | 19900        |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 99500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -7.11        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 19899        |\n",
            "|    policy_loss        | 0.0997       |\n",
            "|    reward             | -0.010994303 |\n",
            "|    std                | 296          |\n",
            "|    value_loss         | 0.000311     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 1849          |\n",
            "|    iterations         | 20000         |\n",
            "|    time_elapsed       | 54            |\n",
            "|    total_timesteps    | 100000        |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -7.13         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 19999         |\n",
            "|    policy_loss        | 0.114         |\n",
            "|    reward             | -0.0009157216 |\n",
            "|    std                | 303           |\n",
            "|    value_loss         | 0.000307      |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_a2c = agent.train_model(model=model_a2c, \n",
        "                             tb_log_name='a2c',\n",
        "                             total_timesteps=100000) if if_using_a2c else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zjCWfgsg3sVa"
      },
      "outputs": [],
      "source": [
        "trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRiOtrywfAo1"
      },
      "source": [
        "### Agent 2: DDPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "M2YadjfnLwgt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to results/ddpg\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ddpg = agent.get_model(\"ddpg\")\n",
        "\n",
        "if if_using_ddpg:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/ddpg'\n",
        "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_ddpg.set_logger(new_logger_ddpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tCDa78rqfO_a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 266      |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 13588    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.62e+03 |\n",
            "|    critic_loss     | 0.943    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 13487    |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 265      |\n",
            "|    time_elapsed    | 102      |\n",
            "|    total_timesteps | 27176    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 687      |\n",
            "|    critic_loss     | 19.9     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 27075    |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "day: 3396, episode: 40\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 100000.00\n",
            "total_reward: 0.00\n",
            "total_cost: 0.00\n",
            "total_trades: 0\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 263      |\n",
            "|    time_elapsed    | 154      |\n",
            "|    total_timesteps | 40764    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 315      |\n",
            "|    critic_loss     | 0.072    |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 40663    |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 263      |\n",
            "|    time_elapsed    | 206      |\n",
            "|    total_timesteps | 54352    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 124      |\n",
            "|    critic_loss     | 0.00738  |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 54251    |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "day: 3396, episode: 50\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 100000.00\n",
            "total_reward: 0.00\n",
            "total_cost: 0.00\n",
            "total_trades: 0\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 259      |\n",
            "|    time_elapsed    | 261      |\n",
            "|    total_timesteps | 67940    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 56.8     |\n",
            "|    critic_loss     | 0.42     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 67839    |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 258      |\n",
            "|    time_elapsed    | 315      |\n",
            "|    total_timesteps | 81528    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 27.6     |\n",
            "|    critic_loss     | 0.00431  |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 81427    |\n",
            "|    reward          | 0.0      |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_ddpg = agent.train_model(model=model_ddpg, \n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=90000) if if_using_ddpg else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ne6M2R-WvrUQ"
      },
      "outputs": [],
      "source": [
        "trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gDkU-j-fCmZ"
      },
      "source": [
        "### Agent 3: PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "y5D5PFUhMzSV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to results/ppo\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.01,\n",
        "    \"learning_rate\": 0.00025,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
        "\n",
        "if if_using_ppo:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/ppo'\n",
        "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_ppo.set_logger(new_logger_ppo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Gt8eIQKYM4G3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "| time/              |              |\n",
            "|    fps             | 2734         |\n",
            "|    iterations      | 1            |\n",
            "|    time_elapsed    | 0            |\n",
            "|    total_timesteps | 2048         |\n",
            "| train/             |              |\n",
            "|    reward          | 0.0054412256 |\n",
            "-------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2526          |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 1             |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015558675 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0142       |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | 0.000168      |\n",
            "|    reward               | 0.0071803913  |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.00192       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2475         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033589134 |\n",
            "|    clip_fraction        | 0.0166       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0433       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.0015      |\n",
            "|    reward               | -0.14918742  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.107        |\n",
            "------------------------------------------\n",
            "day: 3396, episode: 60\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 311119.55\n",
            "total_reward: 211119.55\n",
            "total_cost: 846.40\n",
            "total_trades: 3120\n",
            "Sharpe: 0.663\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2453          |\n",
            "|    iterations           | 4             |\n",
            "|    time_elapsed         | 3             |\n",
            "|    total_timesteps      | 8192          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.002051395   |\n",
            "|    clip_fraction        | 0.0084        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.44         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0096        |\n",
            "|    n_updates            | 30            |\n",
            "|    policy_gradient_loss | -0.000692     |\n",
            "|    reward               | -0.0012630608 |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.0676        |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 2443           |\n",
            "|    iterations           | 5              |\n",
            "|    time_elapsed         | 4              |\n",
            "|    total_timesteps      | 10240          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0048338687   |\n",
            "|    clip_fraction        | 0.0365         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.44          |\n",
            "|    explained_variance   | 0              |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.2            |\n",
            "|    n_updates            | 40             |\n",
            "|    policy_gradient_loss | -0.0023        |\n",
            "|    reward               | -2.2168713e-05 |\n",
            "|    std                  | 1.02           |\n",
            "|    value_loss           | 0.534          |\n",
            "--------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 2435           |\n",
            "|    iterations           | 6              |\n",
            "|    time_elapsed         | 5              |\n",
            "|    total_timesteps      | 12288          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0028580497   |\n",
            "|    clip_fraction        | 0.00903        |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.44          |\n",
            "|    explained_variance   | 5.96e-08       |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | -0.0106        |\n",
            "|    n_updates            | 50             |\n",
            "|    policy_gradient_loss | -0.000406      |\n",
            "|    reward               | -0.00039198314 |\n",
            "|    std                  | 1.02           |\n",
            "|    value_loss           | 0.00414        |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2430         |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009043324 |\n",
            "|    clip_fraction        | 0.00166      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00927     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000167    |\n",
            "|    reward               | 0.0020656274 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.000295     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2427          |\n",
            "|    iterations           | 8             |\n",
            "|    time_elapsed         | 6             |\n",
            "|    total_timesteps      | 16384         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011041711 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.45         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0109       |\n",
            "|    n_updates            | 70            |\n",
            "|    policy_gradient_loss | 0.000294      |\n",
            "|    reward               | -7.792886e-05 |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 0.00203       |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2427          |\n",
            "|    iterations           | 9             |\n",
            "|    time_elapsed         | 7             |\n",
            "|    total_timesteps      | 18432         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0010267409  |\n",
            "|    clip_fraction        | 0.00234       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.46         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0138       |\n",
            "|    n_updates            | 80            |\n",
            "|    policy_gradient_loss | -0.000701     |\n",
            "|    reward               | 4.1446736e-05 |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 0.00018       |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2426        |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007658584 |\n",
            "|    clip_fraction        | 0.0601      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | -2.38e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0107     |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00267    |\n",
            "|    reward               | 0.002199378 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.00125     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2427         |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042400686 |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00261      |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    reward               | 0.098911524  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0499       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2415         |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035474047 |\n",
            "|    clip_fraction        | 0.00552      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00413      |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.0003      |\n",
            "|    reward               | 0.0030281083 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.018        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2398         |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011976353 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -0.0842      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.718        |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    reward               | -0.120179765 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 1.5          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2391         |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027782053 |\n",
            "|    clip_fraction        | 0.00605      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.149        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.183        |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00131     |\n",
            "|    reward               | -0.027327808 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.617        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2389          |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 12            |\n",
            "|    total_timesteps      | 30720         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00040986922 |\n",
            "|    clip_fraction        | 9.77e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.47         |\n",
            "|    explained_variance   | 0.0655        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.72          |\n",
            "|    n_updates            | 140           |\n",
            "|    policy_gradient_loss | -0.000484     |\n",
            "|    reward               | -0.0009598833 |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 2.9           |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2388         |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022359882 |\n",
            "|    clip_fraction        | 0.00259      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.104        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.37         |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00118     |\n",
            "|    reward               | -0.36805636  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 5.12         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2389         |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019795564 |\n",
            "|    clip_fraction        | 0.0082       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.594        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0474       |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.000498    |\n",
            "|    reward               | -0.026811892 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.118        |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 2389           |\n",
            "|    iterations           | 18             |\n",
            "|    time_elapsed         | 15             |\n",
            "|    total_timesteps      | 36864          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0018330016   |\n",
            "|    clip_fraction        | 0.0042         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.48          |\n",
            "|    explained_variance   | 0.17           |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 2.51           |\n",
            "|    n_updates            | 170            |\n",
            "|    policy_gradient_loss | -0.000655      |\n",
            "|    reward               | -8.9019406e-05 |\n",
            "|    std                  | 1.06           |\n",
            "|    value_loss           | 6.01           |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2387         |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033914917 |\n",
            "|    clip_fraction        | 0.0139       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.538        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.683        |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00209     |\n",
            "|    reward               | -0.049208187 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 1.37         |\n",
            "------------------------------------------\n",
            "day: 3396, episode: 70\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 634056.44\n",
            "total_reward: 534056.44\n",
            "total_cost: 878.10\n",
            "total_trades: 3191\n",
            "Sharpe: 0.766\n",
            "=================================\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 2388           |\n",
            "|    iterations           | 20             |\n",
            "|    time_elapsed         | 17             |\n",
            "|    total_timesteps      | 40960          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0013196557   |\n",
            "|    clip_fraction        | 0.00381        |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.48          |\n",
            "|    explained_variance   | 0.266          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 1.7            |\n",
            "|    n_updates            | 190            |\n",
            "|    policy_gradient_loss | -0.00186       |\n",
            "|    reward               | -0.00085751474 |\n",
            "|    std                  | 1.07           |\n",
            "|    value_loss           | 4.13           |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2387         |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012083971 |\n",
            "|    clip_fraction        | 0.000781     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.291        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.88         |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.000126    |\n",
            "|    reward               | 0.24357295   |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 3.85         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2387          |\n",
            "|    iterations           | 22            |\n",
            "|    time_elapsed         | 18            |\n",
            "|    total_timesteps      | 45056         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004173094   |\n",
            "|    clip_fraction        | 0.033         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.48         |\n",
            "|    explained_variance   | 0.571         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00372       |\n",
            "|    n_updates            | 210           |\n",
            "|    policy_gradient_loss | -0.00151      |\n",
            "|    reward               | -0.0017888409 |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 0.0764        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2385         |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053447746 |\n",
            "|    clip_fraction        | 0.0282       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.433        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.21         |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00303     |\n",
            "|    reward               | -0.6375717   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 3.24         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2357         |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032131476 |\n",
            "|    clip_fraction        | 0.00327      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.755        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.219        |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    reward               | -0.25722596  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.939        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2358         |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 21           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002563605  |\n",
            "|    clip_fraction        | 0.00405      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.387        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.51         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.000713    |\n",
            "|    reward               | 0.0043020607 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 2.4          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2361          |\n",
            "|    iterations           | 26            |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 53248         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00095746457 |\n",
            "|    clip_fraction        | 0.00278       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.47         |\n",
            "|    explained_variance   | 0.307         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.91          |\n",
            "|    n_updates            | 250           |\n",
            "|    policy_gradient_loss | -0.00124      |\n",
            "|    reward               | 0.93878406    |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 5.45          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2362        |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003553676 |\n",
            "|    clip_fraction        | 0.0202      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.866       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0427      |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00174    |\n",
            "|    reward               | -0.07929567 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.231       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2363         |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011603907 |\n",
            "|    clip_fraction        | 0.00107      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.31         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.23         |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00077     |\n",
            "|    reward               | 0.37856862   |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 6.77         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2364         |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022620452 |\n",
            "|    clip_fraction        | 0.0128       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.461        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.916        |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    reward               | 0.14679232   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 2.79         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2364         |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022913483 |\n",
            "|    clip_fraction        | 0.0104       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.286        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.59         |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00137     |\n",
            "|    reward               | 0.02079712   |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 3.99         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2366         |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 26           |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015989776 |\n",
            "|    clip_fraction        | 0.00269      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.185        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.67         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    reward               | -0.30578792  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 6.47         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2367         |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 27           |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002031191  |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.802        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0844       |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00335     |\n",
            "|    reward               | -0.021809407 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.19         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2368        |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000747328 |\n",
            "|    clip_fraction        | 0.00239     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.276       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.73        |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.000472   |\n",
            "|    reward               | 0.48624513  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 5.32        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2370        |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 29          |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003397433 |\n",
            "|    clip_fraction        | 0.00474     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.413       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.07        |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.00242    |\n",
            "|    reward               | 0.118594445 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 2.63        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2371         |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018753632 |\n",
            "|    clip_fraction        | 0.00322      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.204        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.07         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    reward               | -0.015799664 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 3.28         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2371          |\n",
            "|    iterations           | 36            |\n",
            "|    time_elapsed         | 31            |\n",
            "|    total_timesteps      | 73728         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00095276337 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.47         |\n",
            "|    explained_variance   | 0.27          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 3.45          |\n",
            "|    n_updates            | 350           |\n",
            "|    policy_gradient_loss | -0.000574     |\n",
            "|    reward               | -0.4948845    |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 7.46          |\n",
            "-------------------------------------------\n",
            "day: 3396, episode: 80\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 857557.71\n",
            "total_reward: 757557.71\n",
            "total_cost: 769.67\n",
            "total_trades: 3168\n",
            "Sharpe: 0.823\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2372         |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053930953 |\n",
            "|    clip_fraction        | 0.0325       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.885        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.108        |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00209     |\n",
            "|    reward               | -0.06892626  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.243        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2373         |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037936033 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.385        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.11         |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    reward               | -1.2833284   |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 6.69         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2374         |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 33           |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018174368 |\n",
            "|    clip_fraction        | 0.00796      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.601        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.64         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00348     |\n",
            "|    reward               | -0.0818239   |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 2.55         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2374          |\n",
            "|    iterations           | 40            |\n",
            "|    time_elapsed         | 34            |\n",
            "|    total_timesteps      | 81920         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0018904521  |\n",
            "|    clip_fraction        | 0.0119        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.48         |\n",
            "|    explained_variance   | 0.351         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.32          |\n",
            "|    n_updates            | 390           |\n",
            "|    policy_gradient_loss | -0.00321      |\n",
            "|    reward               | -0.0014529236 |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 2.46          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2372         |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 35           |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028413432 |\n",
            "|    clip_fraction        | 0.0253       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.468        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.92         |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00379     |\n",
            "|    reward               | -0.28414527  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 4.22         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2373         |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 36           |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019668888 |\n",
            "|    clip_fraction        | 0.0172       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.539        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0423       |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    reward               | 0.09855737   |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.152        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2373         |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015052655 |\n",
            "|    clip_fraction        | 0.00732      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.49        |\n",
            "|    explained_variance   | 0.599        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.85         |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.000427    |\n",
            "|    reward               | -0.16142833  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 3.43         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2374        |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005113759 |\n",
            "|    clip_fraction        | 0.0318      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.48       |\n",
            "|    explained_variance   | 0.466       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.13        |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.00422    |\n",
            "|    reward               | 0.031063182 |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 3.4         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2374         |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 38           |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002822788  |\n",
            "|    clip_fraction        | 0.0206       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.209        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.49         |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000938    |\n",
            "|    reward               | -0.014377607 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 2.65         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2375         |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 39           |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020894487 |\n",
            "|    clip_fraction        | 0.016        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.212        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.01         |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    reward               | -1.2859932   |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 5.78         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2375         |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 40           |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042550736 |\n",
            "|    clip_fraction        | 0.0351       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.74         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.248        |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.000983    |\n",
            "|    reward               | 0.03590941   |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.429        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2376         |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 41           |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012999481 |\n",
            "|    clip_fraction        | 0.0084       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.275        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.06         |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    reward               | 0.43906596   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 5.78         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2377         |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023144784 |\n",
            "|    clip_fraction        | 0.0128       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.239        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.49         |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | 0.000978     |\n",
            "|    reward               | -0.08993732  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 4.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2377         |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023286007 |\n",
            "|    clip_fraction        | 0.0217       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.151        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.818        |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00325     |\n",
            "|    reward               | 0.006801855  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 3.11         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2378         |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035001864 |\n",
            "|    clip_fraction        | 0.0477       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.153        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.59         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | 0.000375     |\n",
            "|    reward               | 0.7425828    |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 7.51         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2378         |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024317177 |\n",
            "|    clip_fraction        | 0.026        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.599        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.344        |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    reward               | -0.023002066 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.681        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2377         |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 45           |\n",
            "|    total_timesteps      | 108544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038484705 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.237        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.78         |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    reward               | -1.875019    |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 6.83         |\n",
            "------------------------------------------\n",
            "day: 3396, episode: 90\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 896012.26\n",
            "total_reward: 796012.26\n",
            "total_cost: 910.16\n",
            "total_trades: 3165\n",
            "Sharpe: 0.828\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2378         |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 46           |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025916463 |\n",
            "|    clip_fraction        | 0.013        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.118        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.56         |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.000922    |\n",
            "|    reward               | -0.13738482  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 4.6          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2379         |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 47           |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020678085 |\n",
            "|    clip_fraction        | 0.0178       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.0229       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.02         |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    reward               | 0.023899917  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 2.56         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2380         |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022982666 |\n",
            "|    clip_fraction        | 0.0129       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | 0.112        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.68         |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -5.82e-06    |\n",
            "|    reward               | 0.053345323  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 7.14         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2380         |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 49           |\n",
            "|    total_timesteps      | 116736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050352113 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | 0.621        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.304        |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    reward               | 0.14155136   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.623        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2380         |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 49           |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009130995 |\n",
            "|    clip_fraction        | 0.004        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | 0.191        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.26         |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    reward               | -1.1050503   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 5.9          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2381         |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 50           |\n",
            "|    total_timesteps      | 120832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031065783 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | 0.384        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.97         |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.00393     |\n",
            "|    reward               | 0.34238777   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 3.62         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2381         |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 51           |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033935714 |\n",
            "|    clip_fraction        | 0.0139       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | -0.585       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.507        |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00298     |\n",
            "|    reward               | 0.005407537  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 1.07         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2381         |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 124928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038402735 |\n",
            "|    clip_fraction        | 0.0233       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | -0.0534      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.77         |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -0.00279     |\n",
            "|    reward               | -0.34117484  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 6.03         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2382        |\n",
            "|    iterations           | 62          |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 126976      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002657778 |\n",
            "|    clip_fraction        | 0.0283      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | 0.205       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.165       |\n",
            "|    n_updates            | 610         |\n",
            "|    policy_gradient_loss | -0.0025     |\n",
            "|    reward               | 0.07275754  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.334       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2383         |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 129024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021607007 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | 0.0864       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.863        |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.000271    |\n",
            "|    reward               | -0.13739407  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 3.23         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2383         |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019469546 |\n",
            "|    clip_fraction        | 0.0164       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | 0.164        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.5          |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.000248    |\n",
            "|    reward               | 0.19873917   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 2.95         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2384         |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 55           |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023289258 |\n",
            "|    clip_fraction        | 0.016        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | -0.0696      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.449        |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | 0.000264     |\n",
            "|    reward               | -0.001700535 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.73         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2385         |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 135168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012828513 |\n",
            "|    clip_fraction        | 0.00322      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.105        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.21         |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.000477    |\n",
            "|    reward               | 0.4762678    |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 4.76         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2385        |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 57          |\n",
            "|    total_timesteps      | 137216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002087316 |\n",
            "|    clip_fraction        | 0.00991     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.263       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.262       |\n",
            "|    n_updates            | 660         |\n",
            "|    policy_gradient_loss | -0.000242   |\n",
            "|    reward               | 0.0540576   |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.566       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2382         |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022716364 |\n",
            "|    clip_fraction        | 0.0122       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.154        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.57         |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    reward               | -2.9994617   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 4.85         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2382         |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 59           |\n",
            "|    total_timesteps      | 141312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034758565 |\n",
            "|    clip_fraction        | 0.0284       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.163        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.61         |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -0.0008      |\n",
            "|    reward               | -0.030259605 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 5.55         |\n",
            "------------------------------------------\n",
            "day: 3396, episode: 100\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 818042.79\n",
            "total_reward: 718042.79\n",
            "total_cost: 898.56\n",
            "total_trades: 3197\n",
            "Sharpe: 0.831\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2383         |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 60           |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023239204 |\n",
            "|    clip_fraction        | 0.0164       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.47        |\n",
            "|    explained_variance   | 0.382        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0454       |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.000448    |\n",
            "|    reward               | -0.08360155  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.221        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2383         |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 60           |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053276187 |\n",
            "|    clip_fraction        | 0.0781       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.077        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.4          |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    reward               | -0.03672145  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 5.75         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2384         |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 61           |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016462005 |\n",
            "|    clip_fraction        | 0.0335       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0.376        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.339        |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    reward               | 0.2297681    |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.801        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2385         |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 62           |\n",
            "|    total_timesteps      | 149504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023843204 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.49        |\n",
            "|    explained_variance   | 0.191        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.03         |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | 0.000368     |\n",
            "|    reward               | 0.0003959319 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 5.99         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2386         |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 151552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048972936 |\n",
            "|    clip_fraction        | 0.0441       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.49        |\n",
            "|    explained_variance   | 0.116        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.11         |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | -0.000427    |\n",
            "|    reward               | -0.11805235  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 6.94         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2386         |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 64           |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044854106 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.5         |\n",
            "|    explained_variance   | 0.806        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0505       |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00157     |\n",
            "|    reward               | 0.04881578   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.188        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2387         |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 155648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032300423 |\n",
            "|    clip_fraction        | 0.0129       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.5         |\n",
            "|    explained_variance   | 0.231        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.2          |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    reward               | -0.13740538  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 7.27         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2388          |\n",
            "|    iterations           | 77            |\n",
            "|    time_elapsed         | 66            |\n",
            "|    total_timesteps      | 157696        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0039733085  |\n",
            "|    clip_fraction        | 0.0418        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.5          |\n",
            "|    explained_variance   | 0.668         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.419         |\n",
            "|    n_updates            | 760           |\n",
            "|    policy_gradient_loss | 0.00103       |\n",
            "|    reward               | -0.0028760566 |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 0.926         |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 2388           |\n",
            "|    iterations           | 78             |\n",
            "|    time_elapsed         | 66             |\n",
            "|    total_timesteps      | 159744         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0010296621   |\n",
            "|    clip_fraction        | 0.00811        |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.5           |\n",
            "|    explained_variance   | 0.237          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 2.77           |\n",
            "|    n_updates            | 770            |\n",
            "|    policy_gradient_loss | -0.000154      |\n",
            "|    reward               | -0.00017984265 |\n",
            "|    std                  | 1.09           |\n",
            "|    value_loss           | 5.72           |\n",
            "--------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 2389       |\n",
            "|    iterations           | 79         |\n",
            "|    time_elapsed         | 67         |\n",
            "|    total_timesteps      | 161792     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00260385 |\n",
            "|    clip_fraction        | 0.0188     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.51      |\n",
            "|    explained_variance   | 0.107      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 2.72       |\n",
            "|    n_updates            | 780        |\n",
            "|    policy_gradient_loss | -0.000295  |\n",
            "|    reward               | 0.09571485 |\n",
            "|    std                  | 1.09       |\n",
            "|    value_loss           | 5.93       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2389        |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 68          |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005118151 |\n",
            "|    clip_fraction        | 0.0392      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.857       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0801      |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | -0.00183    |\n",
            "|    reward               | 0.0948651   |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 0.198       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2389         |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 69           |\n",
            "|    total_timesteps      | 165888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029798213 |\n",
            "|    clip_fraction        | 0.0205       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | 0.252        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.06         |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    reward               | -0.5956843   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 7.02         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2389         |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 167936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026519326 |\n",
            "|    clip_fraction        | 0.0165       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | 0.408        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.14         |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.000857    |\n",
            "|    reward               | 0.022393463  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 1.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2388         |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016017061 |\n",
            "|    clip_fraction        | 0.014        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | 0.255        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.15         |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    reward               | 0.0009816261 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 6.52         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2388        |\n",
            "|    iterations           | 84          |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002888337 |\n",
            "|    clip_fraction        | 0.024       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.0825      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.03        |\n",
            "|    n_updates            | 830         |\n",
            "|    policy_gradient_loss | -0.000117   |\n",
            "|    reward               | 0.007557882 |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 8.19        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2388         |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028677494 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | 0.855        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.107        |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | 0.000232     |\n",
            "|    reward               | -0.12313014  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.238        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2388         |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 73           |\n",
            "|    total_timesteps      | 176128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032709772 |\n",
            "|    clip_fraction        | 0.0132       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | 0.312        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.88         |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.000436    |\n",
            "|    reward               | 0.6650544    |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 7.15         |\n",
            "------------------------------------------\n",
            "day: 3396, episode: 110\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 884475.88\n",
            "total_reward: 784475.88\n",
            "total_cost: 901.30\n",
            "total_trades: 3179\n",
            "Sharpe: 0.835\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2388         |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 74           |\n",
            "|    total_timesteps      | 178176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014490482 |\n",
            "|    clip_fraction        | 0.0234       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | 0.404        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.13         |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    reward               | 0.124452375  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 1.85         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2389         |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 75           |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012281124 |\n",
            "|    clip_fraction        | 0.0107       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | 0.158        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.33         |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    reward               | -0.004480739 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 5.35         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2389         |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 76           |\n",
            "|    total_timesteps      | 182272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035723401 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | 0.0934       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.38         |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.00101     |\n",
            "|    reward               | -0.08581057  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 7.5          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2390        |\n",
            "|    iterations           | 90          |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 184320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004485749 |\n",
            "|    clip_fraction        | 0.0392      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.52       |\n",
            "|    explained_variance   | 0.87        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0491      |\n",
            "|    n_updates            | 890         |\n",
            "|    policy_gradient_loss | 7.79e-05    |\n",
            "|    reward               | 0.054228775 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.242       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2391         |\n",
            "|    iterations           | 91           |\n",
            "|    time_elapsed         | 77           |\n",
            "|    total_timesteps      | 186368       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030244398 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | 0.296        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.34         |\n",
            "|    n_updates            | 900          |\n",
            "|    policy_gradient_loss | -0.000865    |\n",
            "|    reward               | 0.8286076    |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 6.62         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2388         |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037710005 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | 0.537        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.33         |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00178     |\n",
            "|    reward               | -0.07849075  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 2.24         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2389         |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009416833 |\n",
            "|    clip_fraction        | 0.00996      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.32         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.93         |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.000426    |\n",
            "|    reward               | 0.0008241303 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 3.76         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2389         |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 80           |\n",
            "|    total_timesteps      | 192512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015888892 |\n",
            "|    clip_fraction        | 0.0216       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.157        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.37         |\n",
            "|    n_updates            | 930          |\n",
            "|    policy_gradient_loss | 0.00133      |\n",
            "|    reward               | -0.4430715   |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 6.74         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2390         |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 81           |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038889702 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.831        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.128        |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | 0.000401     |\n",
            "|    reward               | 0.11015945   |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.283        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2390         |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 82           |\n",
            "|    total_timesteps      | 196608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034965258 |\n",
            "|    clip_fraction        | 0.022        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.256        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.28         |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.0006      |\n",
            "|    reward               | -0.05693818  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 7.71         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2391         |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 83           |\n",
            "|    total_timesteps      | 198656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022499952 |\n",
            "|    clip_fraction        | 0.052        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.304        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.77         |\n",
            "|    n_updates            | 960          |\n",
            "|    policy_gradient_loss | 0.00242      |\n",
            "|    reward               | -0.07097821  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 3.18         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2391         |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 83           |\n",
            "|    total_timesteps      | 200704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017291885 |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.54        |\n",
            "|    explained_variance   | 0.275        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.6          |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | 0.00121      |\n",
            "|    reward               | 0.007328222  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 4.36         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2390        |\n",
            "|    iterations           | 99          |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 202752      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002224051 |\n",
            "|    clip_fraction        | 0.0216      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0.188       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.88        |\n",
            "|    n_updates            | 980         |\n",
            "|    policy_gradient_loss | 0.000698    |\n",
            "|    reward               | 0.15508857  |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 5.7         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2390        |\n",
            "|    iterations           | 100         |\n",
            "|    time_elapsed         | 85          |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004048496 |\n",
            "|    clip_fraction        | 0.0197      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0.873       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0508      |\n",
            "|    n_updates            | 990         |\n",
            "|    policy_gradient_loss | 0.000463    |\n",
            "|    reward               | 0.06799616  |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.156       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2390        |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 206848      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005197648 |\n",
            "|    clip_fraction        | 0.0399      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | 0.321       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.48        |\n",
            "|    n_updates            | 1000        |\n",
            "|    policy_gradient_loss | -0.00294    |\n",
            "|    reward               | 0.9465919   |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 5.12        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2391         |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 87           |\n",
            "|    total_timesteps      | 208896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023353735 |\n",
            "|    clip_fraction        | 0.00381      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | 0.586        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.668        |\n",
            "|    n_updates            | 1010         |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    reward               | -0.0669962   |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 1.32         |\n",
            "------------------------------------------\n",
            "day: 3396, episode: 120\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 448065.87\n",
            "total_reward: 348065.87\n",
            "total_cost: 927.74\n",
            "total_trades: 3158\n",
            "Sharpe: 0.697\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2391         |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 88           |\n",
            "|    total_timesteps      | 210944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011997543 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.385        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.536        |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.000233    |\n",
            "|    reward               | -0.011931907 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 1.66         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2392         |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 89           |\n",
            "|    total_timesteps      | 212992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003688629 |\n",
            "|    clip_fraction        | 0.00884      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | 0.464        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.984        |\n",
            "|    n_updates            | 1030         |\n",
            "|    policy_gradient_loss | -0.00129     |\n",
            "|    reward               | 0.00842024   |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 1.95         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2392         |\n",
            "|    iterations           | 105          |\n",
            "|    time_elapsed         | 89           |\n",
            "|    total_timesteps      | 215040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046525695 |\n",
            "|    clip_fraction        | 0.033        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | 0.162        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0149       |\n",
            "|    n_updates            | 1040         |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    reward               | 0.039237086  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.0693       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2393         |\n",
            "|    iterations           | 106          |\n",
            "|    time_elapsed         | 90           |\n",
            "|    total_timesteps      | 217088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036385637 |\n",
            "|    clip_fraction        | 0.0135       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | 0.419        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.1          |\n",
            "|    n_updates            | 1050         |\n",
            "|    policy_gradient_loss | -0.00142     |\n",
            "|    reward               | 0.17115596   |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 2.67         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2393         |\n",
            "|    iterations           | 107          |\n",
            "|    time_elapsed         | 91           |\n",
            "|    total_timesteps      | 219136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032159626 |\n",
            "|    clip_fraction        | 0.00757      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.631        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.325        |\n",
            "|    n_updates            | 1060         |\n",
            "|    policy_gradient_loss | -0.00235     |\n",
            "|    reward               | -0.026060572 |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 0.815        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2393         |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 92           |\n",
            "|    total_timesteps      | 221184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020424644 |\n",
            "|    clip_fraction        | 0.00425      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.292        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.427        |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -0.000397    |\n",
            "|    reward               | 0.026224218  |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 1.1          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2394        |\n",
            "|    iterations           | 109         |\n",
            "|    time_elapsed         | 93          |\n",
            "|    total_timesteps      | 223232      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008224192 |\n",
            "|    clip_fraction        | 0.04        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.364       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.38        |\n",
            "|    n_updates            | 1080        |\n",
            "|    policy_gradient_loss | -0.00267    |\n",
            "|    reward               | 0.058544125 |\n",
            "|    std                  | 1.16        |\n",
            "|    value_loss           | 3.4         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2394         |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 94           |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018210781 |\n",
            "|    clip_fraction        | 0.0204       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.899        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0816       |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | 0.000802     |\n",
            "|    reward               | -0.2950223   |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.203        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2395         |\n",
            "|    iterations           | 111          |\n",
            "|    time_elapsed         | 94           |\n",
            "|    total_timesteps      | 227328       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020049068 |\n",
            "|    clip_fraction        | 0.0295       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.362        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.9          |\n",
            "|    n_updates            | 1100         |\n",
            "|    policy_gradient_loss | -0.000287    |\n",
            "|    reward               | 1.4517097    |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 5.08         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2395        |\n",
            "|    iterations           | 112         |\n",
            "|    time_elapsed         | 95          |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004665897 |\n",
            "|    clip_fraction        | 0.0453      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.34        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.52        |\n",
            "|    n_updates            | 1110        |\n",
            "|    policy_gradient_loss | -0.00225    |\n",
            "|    reward               | 0.07236344  |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 3.66        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2396        |\n",
            "|    iterations           | 113         |\n",
            "|    time_elapsed         | 96          |\n",
            "|    total_timesteps      | 231424      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001958173 |\n",
            "|    clip_fraction        | 0.0125      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.0796      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.6         |\n",
            "|    n_updates            | 1120        |\n",
            "|    policy_gradient_loss | 0.000208    |\n",
            "|    reward               | 0.00850185  |\n",
            "|    std                  | 1.16        |\n",
            "|    value_loss           | 3.18        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2396         |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 97           |\n",
            "|    total_timesteps      | 233472       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074809305 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.181        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.94         |\n",
            "|    n_updates            | 1130         |\n",
            "|    policy_gradient_loss | 0.00023      |\n",
            "|    reward               | 0.49118322   |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 6.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2396         |\n",
            "|    iterations           | 115          |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 235520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037989132 |\n",
            "|    clip_fraction        | 0.0488       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.832        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.203        |\n",
            "|    n_updates            | 1140         |\n",
            "|    policy_gradient_loss | 0.00476      |\n",
            "|    reward               | -0.059243385 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.305        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2396        |\n",
            "|    iterations           | 116         |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 237568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003306391 |\n",
            "|    clip_fraction        | 0.0332      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.266       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.58        |\n",
            "|    n_updates            | 1150        |\n",
            "|    policy_gradient_loss | -9.99e-05   |\n",
            "|    reward               | 0.12695904  |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 6.03        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2397        |\n",
            "|    iterations           | 117         |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 239616      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009106801 |\n",
            "|    clip_fraction        | 0.0451      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.286       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.91        |\n",
            "|    n_updates            | 1160        |\n",
            "|    policy_gradient_loss | -0.00187    |\n",
            "|    reward               | 0.13840684  |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 3.88        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2398         |\n",
            "|    iterations           | 118          |\n",
            "|    time_elapsed         | 100          |\n",
            "|    total_timesteps      | 241664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015274051 |\n",
            "|    clip_fraction        | 0.0176       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.069        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.08         |\n",
            "|    n_updates            | 1170         |\n",
            "|    policy_gradient_loss | -0.000459    |\n",
            "|    reward               | -0.02081225  |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 2.67         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2398        |\n",
            "|    iterations           | 119         |\n",
            "|    time_elapsed         | 101         |\n",
            "|    total_timesteps      | 243712      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008392303 |\n",
            "|    clip_fraction        | 0.0938      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.206       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.6         |\n",
            "|    n_updates            | 1180        |\n",
            "|    policy_gradient_loss | 0.000722    |\n",
            "|    reward               | 0.41803342  |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 5.54        |\n",
            "-----------------------------------------\n",
            "day: 3396, episode: 130\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 786674.41\n",
            "total_reward: 686674.41\n",
            "total_cost: 924.56\n",
            "total_trades: 3190\n",
            "Sharpe: 0.816\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2399         |\n",
            "|    iterations           | 120          |\n",
            "|    time_elapsed         | 102          |\n",
            "|    total_timesteps      | 245760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019374647 |\n",
            "|    clip_fraction        | 0.0206       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | 0.616        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.198        |\n",
            "|    n_updates            | 1190         |\n",
            "|    policy_gradient_loss | 0.00186      |\n",
            "|    reward               | -0.034122165 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.557        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2399        |\n",
            "|    iterations           | 121         |\n",
            "|    time_elapsed         | 103         |\n",
            "|    total_timesteps      | 247808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008902883 |\n",
            "|    clip_fraction        | 0.0599      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | 0.305       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.3         |\n",
            "|    n_updates            | 1200        |\n",
            "|    policy_gradient_loss | -0.00204    |\n",
            "|    reward               | -0.43689618 |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 5.06        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2399         |\n",
            "|    iterations           | 122          |\n",
            "|    time_elapsed         | 104          |\n",
            "|    total_timesteps      | 249856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007748366  |\n",
            "|    clip_fraction        | 0.0608       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.55        |\n",
            "|    explained_variance   | 0.339        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.68         |\n",
            "|    n_updates            | 1210         |\n",
            "|    policy_gradient_loss | 0.000824     |\n",
            "|    reward               | -0.039887764 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 3.27         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2400          |\n",
            "|    iterations           | 123           |\n",
            "|    time_elapsed         | 104           |\n",
            "|    total_timesteps      | 251904        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00078229257 |\n",
            "|    clip_fraction        | 0.00493       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.56         |\n",
            "|    explained_variance   | -0.121        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.867         |\n",
            "|    n_updates            | 1220          |\n",
            "|    policy_gradient_loss | -0.00195      |\n",
            "|    reward               | -0.005302076  |\n",
            "|    std                  | 1.16          |\n",
            "|    value_loss           | 2.18          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2401        |\n",
            "|    iterations           | 124         |\n",
            "|    time_elapsed         | 105         |\n",
            "|    total_timesteps      | 253952      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006503462 |\n",
            "|    clip_fraction        | 0.0491      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.0811      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.76        |\n",
            "|    n_updates            | 1230        |\n",
            "|    policy_gradient_loss | 0.00101     |\n",
            "|    reward               | 0.2546412   |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 5.47        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2401        |\n",
            "|    iterations           | 125         |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 256000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009232532 |\n",
            "|    clip_fraction        | 0.0557      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.448       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.2         |\n",
            "|    n_updates            | 1240        |\n",
            "|    policy_gradient_loss | 0.00267     |\n",
            "|    reward               | 0.010373917 |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 0.659       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2401        |\n",
            "|    iterations           | 126         |\n",
            "|    time_elapsed         | 107         |\n",
            "|    total_timesteps      | 258048      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006223511 |\n",
            "|    clip_fraction        | 0.0295      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.135       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.63        |\n",
            "|    n_updates            | 1250        |\n",
            "|    policy_gradient_loss | -0.000875   |\n",
            "|    reward               | 3.004349    |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 6.35        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2402        |\n",
            "|    iterations           | 127         |\n",
            "|    time_elapsed         | 108         |\n",
            "|    total_timesteps      | 260096      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008289095 |\n",
            "|    clip_fraction        | 0.0746      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.0439      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.3         |\n",
            "|    n_updates            | 1260        |\n",
            "|    policy_gradient_loss | 0.000354    |\n",
            "|    reward               | -0.13653003 |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 6.05        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2402         |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 109          |\n",
            "|    total_timesteps      | 262144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015371131 |\n",
            "|    clip_fraction        | 0.0311       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0.107        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.41         |\n",
            "|    n_updates            | 1270         |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    reward               | -0.031881962 |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 2.32         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2403        |\n",
            "|    iterations           | 129         |\n",
            "|    time_elapsed         | 109         |\n",
            "|    total_timesteps      | 264192      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006454277 |\n",
            "|    clip_fraction        | 0.0606      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.121       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.61        |\n",
            "|    n_updates            | 1280        |\n",
            "|    policy_gradient_loss | -3.33e-05   |\n",
            "|    reward               | 0.47410163  |\n",
            "|    std                  | 1.16        |\n",
            "|    value_loss           | 8.96        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2403         |\n",
            "|    iterations           | 130          |\n",
            "|    time_elapsed         | 110          |\n",
            "|    total_timesteps      | 266240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051781796 |\n",
            "|    clip_fraction        | 0.0508       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.401        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.428        |\n",
            "|    n_updates            | 1290         |\n",
            "|    policy_gradient_loss | -0.000623    |\n",
            "|    reward               | 0.10504712   |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.994        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2404        |\n",
            "|    iterations           | 131         |\n",
            "|    time_elapsed         | 111         |\n",
            "|    total_timesteps      | 268288      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006399767 |\n",
            "|    clip_fraction        | 0.0317      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | 0.181       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.16        |\n",
            "|    n_updates            | 1300        |\n",
            "|    policy_gradient_loss | 0.00105     |\n",
            "|    reward               | 3.4378057   |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 7.49        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2403        |\n",
            "|    iterations           | 132         |\n",
            "|    time_elapsed         | 112         |\n",
            "|    total_timesteps      | 270336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005982296 |\n",
            "|    clip_fraction        | 0.0434      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.102       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3           |\n",
            "|    n_updates            | 1310        |\n",
            "|    policy_gradient_loss | 4.61e-05    |\n",
            "|    reward               | 0.017663158 |\n",
            "|    std                  | 1.16        |\n",
            "|    value_loss           | 8.02        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2404         |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 113          |\n",
            "|    total_timesteps      | 272384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035528904 |\n",
            "|    clip_fraction        | 0.016        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0.594        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.656        |\n",
            "|    n_updates            | 1320         |\n",
            "|    policy_gradient_loss | -0.000872    |\n",
            "|    reward               | -0.053312406 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 1.79         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2404        |\n",
            "|    iterations           | 134         |\n",
            "|    time_elapsed         | 114         |\n",
            "|    total_timesteps      | 274432      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010091988 |\n",
            "|    clip_fraction        | 0.0496      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | 0.129       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.96        |\n",
            "|    n_updates            | 1330        |\n",
            "|    policy_gradient_loss | -0.000617   |\n",
            "|    reward               | -0.18609987 |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 11.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2404        |\n",
            "|    iterations           | 135         |\n",
            "|    time_elapsed         | 114         |\n",
            "|    total_timesteps      | 276480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017426759 |\n",
            "|    clip_fraction        | 0.0884      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.63        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.399       |\n",
            "|    n_updates            | 1340        |\n",
            "|    policy_gradient_loss | 0.0105      |\n",
            "|    reward               | -0.17784725 |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 1.11        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2405         |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 115          |\n",
            "|    total_timesteps      | 278528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036898674 |\n",
            "|    clip_fraction        | 0.0484       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | 0.249        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.82         |\n",
            "|    n_updates            | 1350         |\n",
            "|    policy_gradient_loss | 0.00315      |\n",
            "|    reward               | -1.965292    |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 9.11         |\n",
            "------------------------------------------\n",
            "day: 3396, episode: 140\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 992098.27\n",
            "total_reward: 892098.27\n",
            "total_cost: 959.35\n",
            "total_trades: 3203\n",
            "Sharpe: 0.853\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2405        |\n",
            "|    iterations           | 137         |\n",
            "|    time_elapsed         | 116         |\n",
            "|    total_timesteps      | 280576      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008365503 |\n",
            "|    clip_fraction        | 0.0394      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.58       |\n",
            "|    explained_variance   | -0.0467     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.29        |\n",
            "|    n_updates            | 1360        |\n",
            "|    policy_gradient_loss | 0.00218     |\n",
            "|    reward               | -0.03612616 |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 8.84        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2405         |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 117          |\n",
            "|    total_timesteps      | 282624       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043009776 |\n",
            "|    clip_fraction        | 0.0249       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0.673        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.432        |\n",
            "|    n_updates            | 1370         |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    reward               | -0.0694993   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.682        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2406         |\n",
            "|    iterations           | 139          |\n",
            "|    time_elapsed         | 118          |\n",
            "|    total_timesteps      | 284672       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075002615 |\n",
            "|    clip_fraction        | 0.0597       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0.206        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 5.87         |\n",
            "|    n_updates            | 1380         |\n",
            "|    policy_gradient_loss | -0.00318     |\n",
            "|    reward               | 0.06957319   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 9.34         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2406         |\n",
            "|    iterations           | 140          |\n",
            "|    time_elapsed         | 119          |\n",
            "|    total_timesteps      | 286720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006511319  |\n",
            "|    clip_fraction        | 0.048        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0.611        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.587        |\n",
            "|    n_updates            | 1390         |\n",
            "|    policy_gradient_loss | 0.00111      |\n",
            "|    reward               | -0.020002222 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 1.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2406         |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 119          |\n",
            "|    total_timesteps      | 288768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.012606166  |\n",
            "|    clip_fraction        | 0.0533       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0.258        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.14         |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | -0.00218     |\n",
            "|    reward               | 0.0013186585 |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 7.85         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 2407       |\n",
            "|    iterations           | 142        |\n",
            "|    time_elapsed         | 120        |\n",
            "|    total_timesteps      | 290816     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01684851 |\n",
            "|    clip_fraction        | 0.0637     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.59      |\n",
            "|    explained_variance   | 0.038      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 5.05       |\n",
            "|    n_updates            | 1410       |\n",
            "|    policy_gradient_loss | 0.00523    |\n",
            "|    reward               | 0.0407238  |\n",
            "|    std                  | 1.18       |\n",
            "|    value_loss           | 10.2       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2407         |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 121          |\n",
            "|    total_timesteps      | 292864       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.012269739  |\n",
            "|    clip_fraction        | 0.0827       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0.884        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.12         |\n",
            "|    n_updates            | 1420         |\n",
            "|    policy_gradient_loss | 0.00193      |\n",
            "|    reward               | -0.008150966 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.318        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2407        |\n",
            "|    iterations           | 144         |\n",
            "|    time_elapsed         | 122         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011269017 |\n",
            "|    clip_fraction        | 0.0779      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | 0.253       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.59        |\n",
            "|    n_updates            | 1430        |\n",
            "|    policy_gradient_loss | 0.00784     |\n",
            "|    reward               | 0.4463013   |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 9.47        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2407        |\n",
            "|    iterations           | 145         |\n",
            "|    time_elapsed         | 123         |\n",
            "|    total_timesteps      | 296960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012733246 |\n",
            "|    clip_fraction        | 0.0669      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | 0.587       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.608       |\n",
            "|    n_updates            | 1440        |\n",
            "|    policy_gradient_loss | 0.00396     |\n",
            "|    reward               | -0.1099055  |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 1.51        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2407         |\n",
            "|    iterations           | 146          |\n",
            "|    time_elapsed         | 124          |\n",
            "|    total_timesteps      | 299008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064788433 |\n",
            "|    clip_fraction        | 0.0263       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.6         |\n",
            "|    explained_variance   | 0.279        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 4.52         |\n",
            "|    n_updates            | 1450         |\n",
            "|    policy_gradient_loss | 0.00154      |\n",
            "|    reward               | 0.0028159476 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 9.27         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2407        |\n",
            "|    iterations           | 147         |\n",
            "|    time_elapsed         | 125         |\n",
            "|    total_timesteps      | 301056      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022017585 |\n",
            "|    clip_fraction        | 0.0744      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | 0.0404      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.91        |\n",
            "|    n_updates            | 1460        |\n",
            "|    policy_gradient_loss | 0.00765     |\n",
            "|    reward               | 0.08698852  |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 10.6        |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo, \n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=300000) if if_using_ppo else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "C6AidlWyvwzm"
      },
      "outputs": [],
      "source": [
        "trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zpv4S0-fDBv"
      },
      "source": [
        "### Agent 4: TD3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "JSAHhV4Xc-bh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to results/td3\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "TD3_PARAMS = {\"batch_size\": 100, \n",
        "              \"buffer_size\": 1000000, \n",
        "              \"learning_rate\": 0.001}\n",
        "\n",
        "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
        "\n",
        "if if_using_td3:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/td3'\n",
        "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_td3.set_logger(new_logger_td3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "OSRxNYAxdKpU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 3396, episode: 150\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1340888.53\n",
            "total_reward: 1240888.53\n",
            "total_cost: 99.89\n",
            "total_trades: 3396\n",
            "Sharpe: 0.883\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 270        |\n",
            "|    time_elapsed    | 50         |\n",
            "|    total_timesteps | 13588      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -290       |\n",
            "|    critic_loss     | 39.3       |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 13487      |\n",
            "|    reward          | -2.4616802 |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 8          |\n",
            "|    fps             | 269        |\n",
            "|    time_elapsed    | 100        |\n",
            "|    total_timesteps | 27176      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -124       |\n",
            "|    critic_loss     | 4.88       |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 27075      |\n",
            "|    reward          | -2.4616802 |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 12         |\n",
            "|    fps             | 264        |\n",
            "|    time_elapsed    | 154        |\n",
            "|    total_timesteps | 40764      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -82.5      |\n",
            "|    critic_loss     | 2.64       |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 40663      |\n",
            "|    reward          | -2.4616802 |\n",
            "-----------------------------------\n",
            "day: 3396, episode: 160\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1340888.53\n",
            "total_reward: 1240888.53\n",
            "total_cost: 99.89\n",
            "total_trades: 3396\n",
            "Sharpe: 0.883\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 16         |\n",
            "|    fps             | 262        |\n",
            "|    time_elapsed    | 206        |\n",
            "|    total_timesteps | 54352      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -53.7      |\n",
            "|    critic_loss     | 2.34       |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 54251      |\n",
            "|    reward          | -2.4616802 |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 20         |\n",
            "|    fps             | 261        |\n",
            "|    time_elapsed    | 260        |\n",
            "|    total_timesteps | 67940      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -29        |\n",
            "|    critic_loss     | 2.98       |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 67839      |\n",
            "|    reward          | -2.4616802 |\n",
            "-----------------------------------\n",
            "day: 3396, episode: 170\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1340888.53\n",
            "total_reward: 1240888.53\n",
            "total_cost: 99.89\n",
            "total_trades: 3396\n",
            "Sharpe: 0.883\n",
            "=================================\n"
          ]
        }
      ],
      "source": [
        "trained_td3 = agent.train_model(model=model_td3, \n",
        "                             tb_log_name='td3',\n",
        "                             total_timesteps=80000) if if_using_td3 else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OkJV6V_mv2hw"
      },
      "outputs": [],
      "source": [
        "trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr49PotrfG01"
      },
      "source": [
        "### Agent 5: SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "xwOhVjqRkCdM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to results/sac\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "SAC_PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"learning_starts\": 100,\n",
        "    \"ent_coef\": \"auto_0.1\",\n",
        "}\n",
        "\n",
        "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
        "\n",
        "if if_using_sac:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/sac'\n",
        "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_sac.set_logger(new_logger_sac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "K8RSdKCckJyH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 215        |\n",
            "|    time_elapsed    | 63         |\n",
            "|    total_timesteps | 13588      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 44.5       |\n",
            "|    critic_loss     | 4.25       |\n",
            "|    ent_coef        | 0.339      |\n",
            "|    ent_coef_loss   | 10.2       |\n",
            "|    learning_rate   | 0.0001     |\n",
            "|    n_updates       | 13487      |\n",
            "|    reward          | -2.4616802 |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 8          |\n",
            "|    fps             | 218        |\n",
            "|    time_elapsed    | 124        |\n",
            "|    total_timesteps | 27176      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 447        |\n",
            "|    critic_loss     | 11.8       |\n",
            "|    ent_coef        | 1.32       |\n",
            "|    ent_coef_loss   | -2.57      |\n",
            "|    learning_rate   | 0.0001     |\n",
            "|    n_updates       | 27075      |\n",
            "|    reward          | -2.4616802 |\n",
            "-----------------------------------\n",
            "day: 3396, episode: 180\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 1340888.53\n",
            "total_reward: 1240888.53\n",
            "total_cost: 99.89\n",
            "total_trades: 3396\n",
            "Sharpe: 0.883\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 12         |\n",
            "|    fps             | 214        |\n",
            "|    time_elapsed    | 189        |\n",
            "|    total_timesteps | 40764      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 1.86e+03   |\n",
            "|    critic_loss     | 44.4       |\n",
            "|    ent_coef        | 5.13       |\n",
            "|    ent_coef_loss   | -15.3      |\n",
            "|    learning_rate   | 0.0001     |\n",
            "|    n_updates       | 40663      |\n",
            "|    reward          | -2.4616802 |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 16         |\n",
            "|    fps             | 212        |\n",
            "|    time_elapsed    | 255        |\n",
            "|    total_timesteps | 54352      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 7.21e+03   |\n",
            "|    critic_loss     | 399        |\n",
            "|    ent_coef        | 20         |\n",
            "|    ent_coef_loss   | -28        |\n",
            "|    learning_rate   | 0.0001     |\n",
            "|    n_updates       | 54251      |\n",
            "|    reward          | -2.4616802 |\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_sac = agent.train_model(model=model_sac, \n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=60000) if if_using_sac else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_SpZoQgPv7GO"
      },
      "outputs": [],
      "source": [
        "trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgGm3dQZfRks"
      },
      "source": [
        "## Save the trained agent\n",
        "Trained agents should have already been saved in the \"trained_models\" drectory after you run the code blocks above.\n",
        "\n",
        "For Colab users, the zip files should be at \"./trained_models\" or \"/content/trained_models\".\n",
        "\n",
        "For users running on your local environment, the zip files should be at \"./trained_models\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MRiOtrywfAo1",
        "_gDkU-j-fCmZ",
        "3Zpv4S0-fDBv",
        "Dr49PotrfG01"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
